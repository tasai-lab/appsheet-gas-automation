// Vertex AI Client v2.0
const VERTEX_CONFIG = {projectId: "tasai-project-443908", location: "us-central1", models: {PRO: 'gemini-2.5-pro', FLASH: 'gemini-2.5-flash'}, defaults: {temperature: 0.3, maxOutputTokens: 20000, topP: 0.95, topK: 40}};
class GeminiClient {constructor(model, options) {model = model || VERTEX_CONFIG.models.FLASH; options = options || {}; this.model = model; this.temperature = options.temperature !== undefined ? options.temperature : VERTEX_CONFIG.defaults.temperature; this.maxOutputTokens = options.maxOutputTokens || VERTEX_CONFIG.defaults.maxOutputTokens; this.topP = options.topP !== undefined ? options.topP : VERTEX_CONFIG.defaults.topP; this.topK = options.topK !== undefined ? options.topK : VERTEX_CONFIG.defaults.topK; this.enableThinking = options.enableThinking !== undefined ? options.enableThinking : true; this.thinkingBudget = options.thinkingBudget !== undefined ? options.thinkingBudget : -1;} generateText(prompt, logger) {var url = 'https://' + VERTEX_CONFIG.location + '-aiplatform.googleapis.com/v1/projects/' + VERTEX_CONFIG.projectId + '/locations/' + VERTEX_CONFIG.location + '/publishers/google/models/' + this.model + ':generateContent'; var body = {contents: [{role: 'user', parts: [{text: prompt}]}], generationConfig: {temperature: this.temperature, maxOutputTokens: this.maxOutputTokens, topP: this.topP, topK: this.topK}}; if (this.enableThinking) body.generationConfig.thinkingConfig = {thinkingBudget: this.thinkingBudget}; var opts = {method: 'post', contentType: 'application/json', payload: JSON.stringify(body), headers: {'Authorization': 'Bearer ' + ScriptApp.getOAuthToken()}, muteHttpExceptions: true}; var res = UrlFetchApp.fetch(url, opts); if (res.getResponseCode() !== 200) throw new Error('Vertex AI error'); return JSON.parse(res.getContentText()).candidates[0].content.parts[0].text.trim();} generateJSON(prompt, logger) {var text = this.generateText(prompt, logger); var match = text.match(/```json\s*([\s\S]*?)\s*```/); return JSON.parse(match ? match[1].trim() : text.trim());} generateChat(messages, logger) {var contents = []; for (var i = 0; i < messages.length; i++) contents.push({role: messages[i].role === 'user' ? 'user' : 'model', parts: [{text: messages[i].text}]}); var url = 'https://' + VERTEX_CONFIG.location + '-aiplatform.googleapis.com/v1/projects/' + VERTEX_CONFIG.projectId + '/locations/' + VERTEX_CONFIG.location + '/publishers/google/models/' + this.model + ':generateContent'; var body = {contents: contents, generationConfig: {temperature: this.temperature, maxOutputTokens: this.maxOutputTokens, topP: this.topP, topK: this.topK}}; if (this.enableThinking) body.generationConfig.thinkingConfig = {thinkingBudget: this.thinkingBudget}; var opts = {method: 'post', contentType: 'application/json', payload: JSON.stringify(body), headers: {'Authorization': 'Bearer ' + ScriptApp.getOAuthToken()}, muteHttpExceptions: true}; return JSON.parse(UrlFetchApp.fetch(url, opts).getContentText()).candidates[0].content.parts[0].text.trim();} updateConfig(config) {if (config.temperature !== undefined) this.temperature = config.temperature; if (config.maxOutputTokens !== undefined) this.maxOutputTokens = config.maxOutputTokens; if (config.topP !== undefined) this.topP = config.topP; if (config.topK !== undefined) this.topK = config.topK;}}
function createGeminiProClient(options) {return new GeminiClient(VERTEX_CONFIG.models.PRO, options || {});}
function createGeminiFlashClient(options) {return new GeminiClient(VERTEX_CONFIG.models.FLASH, options || {});}
function createGeminiClient(model, options) {return new GeminiClient(model, options || {});}
