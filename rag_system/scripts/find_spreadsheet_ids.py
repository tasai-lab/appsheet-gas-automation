#!/usr/bin/env python3
"""
GASãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰Spreadsheet IDã‚’è‡ªå‹•æŠ½å‡ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    python scripts/find_spreadsheet_ids.py
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
ROOT_DIR = Path(__file__).parent.parent.parent
GAS_PROJECTS_DIR = ROOT_DIR / "gas_projects"
DATA_SOURCES_FILE = Path(__file__).parent / "data_sources.json"

# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åã¨GASãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã®ãƒãƒƒãƒ”ãƒ³ã‚°
DATA_SOURCE_TO_GAS_PROJECT = {
    "nursing_regular": "Appsheet_è¨ªå•çœ‹è­·_é€šå¸¸è¨˜éŒ²",
    "nursing_mental": "Appsheet_è¨ªå•çœ‹è­·_ç²¾ç¥ç§‘è¨˜éŒ²",
    "nursing_plan": "Appsheet_è¨ªå•çœ‹è­·_è¨ˆç”»æ›¸å•é¡Œç‚¹",
    "nursing_plan_eval": "Appsheet_è¨ªå•çœ‹è­·_è¨ˆç”»æ›¸å•é¡Œç‚¹_è©•ä¾¡",
    "nursing_report": "Appsheet_è¨ªå•çœ‹è­·_å ±å‘Šæ›¸",
    "clients_basic": "Appsheet_åˆ©ç”¨è€…_åŸºæœ¬æƒ…å ±ä¸Šæ›¸ã",  # ã¾ãŸã¯ Appsheet_åˆ©ç”¨è€…_åæ˜ 
    "clients_qa": "Appsheet_åˆ©ç”¨è€…_è³ªç–‘å¿œç­”",
    "clients_facesheet": "Appsheet_åˆ©ç”¨è€…_ãƒ•ã‚§ãƒ¼ã‚¹ã‚·ãƒ¼ãƒˆ",
    "clients_family": "Appsheet_åˆ©ç”¨è€…_å®¶æ—æƒ…å ±ä½œæˆ",
    "calls_summary": "Appsheet_é€šè©±_è¦ç´„ç”Ÿæˆ",
    "calls_qa": "Appsheet_é€šè©±_è³ªç–‘å¿œç­”",
    "calls_threads": "Appsheet_ALL_ã‚¹ãƒ¬ãƒƒãƒ‰æ›´æ–°",
    "sales_report": "Appsheet_å–¶æ¥­ãƒ¬ãƒãƒ¼ãƒˆ",
    "sales_card": "Appsheet_ååˆºå–ã‚Šè¾¼ã¿",
    "automation_receipt": "Automation_ãƒ¬ã‚·ãƒ¼ãƒˆ",
}


def find_spreadsheet_id_in_file(file_path: Path) -> Optional[str]:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«å†…ã‹ã‚‰Spreadsheet IDã‚’æŠ½å‡º

    ãƒ‘ã‚¿ãƒ¼ãƒ³:
    - const TARGET_SPREADSHEET_ID = '1ABC...XYZ';
    - const DATA_SPREADSHEET_ID = '1ABC...XYZ';
    - const SPREADSHEET_ID = '1ABC...XYZ';
    """
    try:
        content = file_path.read_text(encoding='utf-8')

        # EXECUTION_LOG_SPREADSHEET_IDã¯é™¤å¤–
        patterns = [
            r'(?:TARGET_SPREADSHEET_ID|DATA_SPREADSHEET_ID|SPREADSHEET_ID)\s*=\s*["\']([a-zA-Z0-9_-]{30,})["\']',
        ]

        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                spreadsheet_id = match.group(1)
                # å®Ÿè¡Œãƒ­ã‚°Spreadsheet IDã¯é™¤å¤–
                if spreadsheet_id != "16UHnMlSUlnUy-67gbwuvjeeU73AwDomqzJwGi6L4rVA":
                    return spreadsheet_id

        return None

    except Exception as e:
        print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path}: {e}")
        return None


def find_gas_project_dir(project_name: str) -> Optional[Path]:
    """GASãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢"""
    for root, dirs, files in os.walk(GAS_PROJECTS_DIR):
        for dir_name in dirs:
            if dir_name == project_name:
                return Path(root) / dir_name
    return None


def extract_spreadsheet_ids() -> Dict[str, Optional[str]]:
    """å…¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®Spreadsheet IDã‚’æŠ½å‡º"""
    results = {}

    for data_source_key, gas_project_name in DATA_SOURCE_TO_GAS_PROJECT.items():
        print(f"\nğŸ” æ¤œç´¢ä¸­: {data_source_key} ({gas_project_name})")

        # GASãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
        project_dir = find_gas_project_dir(gas_project_name)

        if not project_dir:
            print(f"  âŒ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {gas_project_name}")
            results[data_source_key] = None
            continue

        print(f"  ğŸ“ è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {project_dir}")

        # config.gs / Config.gs ã‚’æ¤œç´¢
        config_files = list(project_dir.rglob("config.gs")) + list(project_dir.rglob("Config.gs"))

        if not config_files:
            print(f"  âš ï¸ config.gs ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            results[data_source_key] = None
            continue

        # Spreadsheet IDã‚’æŠ½å‡º
        for config_file in config_files:
            spreadsheet_id = find_spreadsheet_id_in_file(config_file)
            if spreadsheet_id:
                print(f"  âœ… è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {spreadsheet_id}")
                print(f"     ãƒ•ã‚¡ã‚¤ãƒ«: {config_file}")
                results[data_source_key] = spreadsheet_id
                break
        else:
            print(f"  âš ï¸ Spreadsheet IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            results[data_source_key] = None

    return results


def update_data_sources_json(spreadsheet_ids: Dict[str, Optional[str]]):
    """data_sources.jsonã‚’æ›´æ–°"""
    if not DATA_SOURCES_FILE.exists():
        print(f"\nâŒ {DATA_SOURCES_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    with open(DATA_SOURCES_FILE, 'r', encoding='utf-8') as f:
        data_sources = json.load(f)

    updated_count = 0
    for data_source_key, spreadsheet_id in spreadsheet_ids.items():
        if spreadsheet_id and data_source_key in data_sources:
            data_sources[data_source_key]['spreadsheet_id'] = spreadsheet_id
            updated_count += 1

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_file = DATA_SOURCES_FILE.parent / "data_sources.json.backup"
    DATA_SOURCES_FILE.rename(backup_file)
    print(f"\nğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")

    # æ›´æ–°ã—ãŸJSONã‚’ä¿å­˜
    with open(DATA_SOURCES_FILE, 'w', encoding='utf-8') as f:
        json.dump(data_sources, f, ensure_ascii=False, indent=2)

    print(f"âœ… {DATA_SOURCES_FILE} ã‚’æ›´æ–°ã—ã¾ã—ãŸ ({updated_count}ä»¶)")


def main():
    print("=" * 60)
    print("GASãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰Spreadsheet IDã‚’è‡ªå‹•æŠ½å‡º")
    print("=" * 60)

    # Spreadsheet IDã‚’æŠ½å‡º
    spreadsheet_ids = extract_spreadsheet_ids()

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "=" * 60)
    print("æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)

    found_count = sum(1 for sid in spreadsheet_ids.values() if sid)
    total_count = len(spreadsheet_ids)

    print(f"\nâœ… è¦‹ã¤ã‹ã£ãŸ: {found_count} / {total_count}")
    print(f"âŒ è¦‹ã¤ã‹ã‚‰ãªã„: {total_count - found_count} / {total_count}")

    print("\nã€è©³ç´°ã€‘")
    for data_source_key, spreadsheet_id in spreadsheet_ids.items():
        status = "âœ…" if spreadsheet_id else "âŒ"
        print(f"  {status} {data_source_key:20s} : {spreadsheet_id or 'æœªè¨­å®š'}")

    # data_sources.jsonã‚’æ›´æ–°
    if found_count > 0:
        print("\n" + "=" * 60)
        update_data_sources_json(spreadsheet_ids)
    else:
        print("\nâš ï¸ Spreadsheet IDãŒ1ã¤ã‚‚è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€data_sources.jsonã¯æ›´æ–°ã—ã¾ã›ã‚“")

    print("\n" + "=" * 60)
    print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("=" * 60)
    print(f"1. {DATA_SOURCES_FILE} ã‚’é–‹ã„ã¦ã€æœªè¨­å®šã®Spreadsheet IDã‚’æ‰‹å‹•ã§å…¥åŠ›")
    print("2. python scripts/vectorize_existing_data.py --list-sources ã§ç¢ºèª")
    print("3. python scripts/vectorize_existing_data.py --all --dry-run ã§ãƒ†ã‚¹ãƒˆ")


if __name__ == "__main__":
    main()
