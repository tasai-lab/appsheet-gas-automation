#!/usr/bin/env python3
"""
Phase 5.3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®šã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¸¬å®šã€ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
import requests
import statistics
from pathlib import Path
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv

# .envèª­ã¿è¾¼ã¿
env_path = project_root / 'backend' / '.env'
load_dotenv(env_path)

BASE_URL = os.getenv("BASE_URL", "http://localhost:8000")


def measure_search_latency(query: str, iterations: int = 10) -> Dict[str, float]:
    """æ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®š"""
    latencies = []

    payload = {
        "query": query,
        "client_id": None,
        "limit": 10
    }

    for i in range(iterations):
        start_time = time.time()
        response = requests.post(f"{BASE_URL}/api/search", json=payload)
        elapsed_time = time.time() - start_time

        if response.status_code == 200:
            latencies.append(elapsed_time)
        else:
            print(f"  âš ï¸ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {response.status_code}")

    return {
        "min": min(latencies) * 1000 if latencies else 0,
        "max": max(latencies) * 1000 if latencies else 0,
        "mean": statistics.mean(latencies) * 1000 if latencies else 0,
        "median": statistics.median(latencies) * 1000 if latencies else 0,
        "p95": statistics.quantiles(latencies, n=20)[18] * 1000 if len(latencies) >= 20 else 0,
        "p99": statistics.quantiles(latencies, n=100)[98] * 1000 if len(latencies) >= 100 else 0,
    }


def test_latency():
    """ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*70)
    print("Phase 5.3-A: ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®š")
    print("="*70)

    test_queries = [
        "è¨ªå•çœ‹è­·è¨ˆç”»",
        "åˆ©ç”¨è€…åŸºæœ¬æƒ…å ±",
        "é€šè©±è¨˜éŒ²è¦ç´„",
    ]

    all_results = []

    for query in test_queries:
        print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: '{query}'ï¼ˆ10å›å®Ÿè¡Œï¼‰")

        results = measure_search_latency(query, iterations=10)
        all_results.append(results)

        print(f"  - æœ€å°: {results['min']:.2f}ms")
        print(f"  - æœ€å¤§: {results['max']:.2f}ms")
        print(f"  - å¹³å‡: {results['mean']:.2f}ms")
        print(f"  - ä¸­å¤®å€¤: {results['median']:.2f}ms")
        print(f"  - P95: {results['p95']:.2f}ms" if results['p95'] > 0 else "  - P95: N/A")

    # å…¨ä½“å¹³å‡
    avg_latency = statistics.mean([r['mean'] for r in all_results])
    print(f"\nğŸ“ˆ ç·åˆå¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {avg_latency:.2f}ms")

    if avg_latency < 500:
        print("âœ… å„ªç§€ï¼ˆ< 500msï¼‰")
    elif avg_latency < 1000:
        print("âœ… è‰¯å¥½ï¼ˆ< 1000msï¼‰")
    elif avg_latency < 2000:
        print("âš ï¸ æ”¹å–„ä½™åœ°ã‚ã‚Šï¼ˆ< 2000msï¼‰")
    else:
        print("âŒ è¦æ”¹å–„ï¼ˆ>= 2000msï¼‰")

    return avg_latency


def measure_throughput(query: str, concurrent_requests: int = 10, duration_sec: int = 30) -> Dict[str, Any]:
    """ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¸¬å®š"""
    def send_request():
        payload = {
            "query": query,
            "client_id": None,
            "limit": 10
        }
        start_time = time.time()
        try:
            response = requests.post(f"{BASE_URL}/api/search", json=payload, timeout=10)
            elapsed_time = time.time() - start_time
            return {
                "success": response.status_code == 200,
                "latency": elapsed_time,
                "status_code": response.status_code
            }
        except Exception as e:
            return {
                "success": False,
                "latency": time.time() - start_time,
                "error": str(e)
            }

    start_time = time.time()
    end_time = start_time + duration_sec
    results = []

    with ThreadPoolExecutor(max_workers=concurrent_requests) as executor:
        futures = []

        while time.time() < end_time:
            # åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
            for _ in range(concurrent_requests):
                if time.time() >= end_time:
                    break
                future = executor.submit(send_request)
                futures.append(future)

            # å°‘ã—å¾…æ©Ÿã—ã¦ã‹ã‚‰æ¬¡ã®ãƒãƒƒãƒ
            time.sleep(0.5)

        # å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Œäº†ã‚’å¾…ã¤
        for future in as_completed(futures):
            results.append(future.result())

    total_duration = time.time() - start_time
    successful_requests = sum(1 for r in results if r["success"])
    failed_requests = len(results) - successful_requests

    return {
        "total_requests": len(results),
        "successful_requests": successful_requests,
        "failed_requests": failed_requests,
        "success_rate": successful_requests / len(results) * 100 if results else 0,
        "throughput_rps": successful_requests / total_duration,
        "avg_latency": statistics.mean([r["latency"] for r in results if r["success"]]) * 1000 if successful_requests > 0 else 0,
    }


def test_throughput():
    """ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*70)
    print("Phase 5.3-B: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¸¬å®š")
    print("="*70)

    query = "è¨ªå•çœ‹è­·è¨ˆç”»"
    concurrent_requests = 5
    duration_sec = 10

    print(f"\nğŸ“Š ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {concurrent_requests}")
    print(f"ğŸ“Š æ¸¬å®šæ™‚é–“: {duration_sec}ç§’")
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: '{query}'")
    print("\nâ³ æ¸¬å®šä¸­...\n")

    results = measure_throughput(query, concurrent_requests, duration_sec)

    print(f"  - ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {results['total_requests']}")
    print(f"  - æˆåŠŸ: {results['successful_requests']}")
    print(f"  - å¤±æ•—: {results['failed_requests']}")
    print(f"  - æˆåŠŸç‡: {results['success_rate']:.1f}%")
    print(f"  - ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {results['throughput_rps']:.2f} req/s")
    print(f"  - å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {results['avg_latency']:.2f}ms")

    if results['success_rate'] >= 99 and results['throughput_rps'] >= 5:
        print("\nâœ… å„ªç§€ï¼ˆæˆåŠŸç‡ >= 99%, ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ >= 5 req/sï¼‰")
    elif results['success_rate'] >= 95 and results['throughput_rps'] >= 3:
        print("\nâœ… è‰¯å¥½ï¼ˆæˆåŠŸç‡ >= 95%, ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ >= 3 req/sï¼‰")
    else:
        print("\nâš ï¸ æ”¹å–„ä½™åœ°ã‚ã‚Š")

    return results


def test_stress():
    """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*70)
    print("Phase 5.3-C: ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("="*70)

    query = "çœ‹è­·è¨˜éŒ²"
    max_concurrent = 20

    print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: '{query}'")
    print(f"ğŸ“Š æœ€å¤§ä¸¦è¡Œæ•°: {max_concurrent}")
    print("\nâ³ æ¸¬å®šä¸­...\n")

    stress_results = []

    for concurrent in [1, 5, 10, 15, 20]:
        print(f"  ğŸ”„ ä¸¦è¡Œæ•°: {concurrent}")

        results = measure_throughput(query, concurrent, duration_sec=5)

        stress_results.append({
            "concurrent": concurrent,
            "throughput": results['throughput_rps'],
            "success_rate": results['success_rate'],
            "avg_latency": results['avg_latency']
        })

        print(f"    - ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {results['throughput_rps']:.2f} req/s")
        print(f"    - æˆåŠŸç‡: {results['success_rate']:.1f}%")
        print(f"    - å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {results['avg_latency']:.2f}ms\n")

    # æœ€é©ä¸¦è¡Œæ•°ã®æ¨å®š
    best_throughput = max(stress_results, key=lambda x: x['throughput'])
    print(f"\nğŸ“ˆ æœ€é©ä¸¦è¡Œæ•°: {best_throughput['concurrent']}")
    print(f"   æœ€å¤§ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {best_throughput['throughput']:.2f} req/s")

    return stress_results


def run_performance_test():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""

    print(f"\n{'='*70}")
    print("Phase 5.3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
    print(f"{'='*70}")
    print(f"Backend URL: {BASE_URL}")
    print(f"{'='*70}\n")

    try:
        # Phase 5.3-A: ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ¸¬å®š
        avg_latency = test_latency()

        # Phase 5.3-B: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¸¬å®š
        throughput_results = test_throughput()

        # Phase 5.3-C: ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
        stress_results = test_stress()

        # ã‚µãƒãƒªãƒ¼
        print(f"\n{'='*70}")
        print("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print(f"{'='*70}")
        print(f"å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {avg_latency:.2f}ms")
        print(f"ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput_results['throughput_rps']:.2f} req/s")
        print(f"æˆåŠŸç‡: {throughput_results['success_rate']:.1f}%")

        # ç·åˆè©•ä¾¡
        if (avg_latency < 1000 and
            throughput_results['throughput_rps'] >= 5 and
            throughput_results['success_rate'] >= 99):
            print("\nğŸ‰ Phase 5.3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆåˆæ ¼ï¼")
            print("æ¬¡ã®Phase: Phase 4.4ï¼ˆVercelãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰")
            return True
        elif (avg_latency < 2000 and
              throughput_results['throughput_rps'] >= 3 and
              throughput_results['success_rate'] >= 95):
            print("\nâœ… Phase 5.3: è‰¯å¥½ - æœ¬ç•ªç’°å¢ƒã§ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ¨å¥¨")
            return True
        else:
            print("\nâš ï¸ Phase 5.3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã‚’æ¨å¥¨")
            return False

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    try:
        success = run_performance_test()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
