#!/usr/bin/env python3
"""
GASãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰è©³ç´°ã«Spreadsheet IDã‚’æŠ½å‡º

å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®README.md, SPECIFICATIONS.md, config*.gs, *.mdã‚’è§£æã—ã¦
Spreadsheet IDã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã™ã€‚
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Tuple

ROOT_DIR = Path(__file__).parent.parent.parent
GAS_PROJECTS_DIR = ROOT_DIR / "gas_projects" / "projects"

# é™¤å¤–ã™ã‚‹Spreadsheet IDï¼ˆå®Ÿè¡Œãƒ­ã‚°ã€Vector DBã€ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼IDï¼‰
EXCLUDE_IDS = {
    "16UHnMlSUlnUy-67gbwuvjeeU73AwDomqzJwGi6L4rVA",  # å®Ÿè¡Œãƒ­ã‚°
    "16swPUizvdlyPxUjbDpVl9-VBDJZO91kX",  # å®Ÿè¡Œãƒ­ã‚°ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼
    "1roSp4WKubXVzZ6iWd6OY5lMU5OpvFsVNQHy11_Ym-wA",  # Vector DB
}

# æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆSpreadsheet IDã¯é€šå¸¸30-50æ–‡å­—ï¼‰
SPREADSHEET_ID_PATTERN = re.compile(r'\b(1[a-zA-Z0-9_-]{30,50})\b')

# Access Keyã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆé™¤å¤–ç”¨ï¼‰
ACCESS_KEY_PATTERN = re.compile(r'V2-[a-zA-Z0-9]{5,}')

# GASãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã¨data_sourcesã®ãƒãƒƒãƒ”ãƒ³ã‚°
PROJECT_NAME_MAPPING = {
    "Appsheet_è¨ªå•çœ‹è­·_é€šå¸¸è¨˜éŒ²": "nursing_regular",
    "Appsheet_è¨ªå•çœ‹è­·_ç²¾ç¥ç§‘è¨˜éŒ²": "nursing_mental",
    "Appsheet_è¨ªå•çœ‹è­·_è¨ˆç”»æ›¸å•é¡Œç‚¹": "nursing_plan",
    "Appsheet_è¨ªå•çœ‹è­·_è¨ˆç”»æ›¸å•é¡Œç‚¹_è©•ä¾¡": "nursing_plan_eval",
    "Appsheet_è¨ªå•çœ‹è­·_å ±å‘Šæ›¸": "nursing_report",
    "Appsheet_åˆ©ç”¨è€…_åŸºæœ¬æƒ…å ±ä¸Šæ›¸ã": "clients_basic",
    "Appsheet_åˆ©ç”¨è€…_è³ªç–‘å¿œç­”": "clients_qa",
    "Appsheet_åˆ©ç”¨è€…_ãƒ•ã‚§ãƒ¼ã‚¹ã‚·ãƒ¼ãƒˆ": "clients_facesheet",
    "Appsheet_åˆ©ç”¨è€…_å®¶æ—æƒ…å ±ä½œæˆ": "clients_family",
    "Appsheet_é€šè©±_è¦ç´„ç”Ÿæˆ": "calls_summary",
    "Appsheet_é€šè©±_è³ªç–‘å¿œç­”": "calls_qa",
    "Appsheet_ALL_ã‚¹ãƒ¬ãƒƒãƒ‰æ›´æ–°": "calls_threads",
    "Appsheet_å–¶æ¥­ãƒ¬ãƒãƒ¼ãƒˆ": "sales_report",
    "Appsheet_ååˆºå–ã‚Šè¾¼ã¿": "sales_card",
    "Automation_ãƒ¬ã‚·ãƒ¼ãƒˆ": "automation_receipt",
}


def is_valid_spreadsheet_id(id_str: str) -> bool:
    """æœ‰åŠ¹ãªSpreadsheet IDã‹ãƒã‚§ãƒƒã‚¯"""
    # é•·ã™ãã‚‹ï¼ˆAccess Keyã®å¯èƒ½æ€§ï¼‰
    if len(id_str) > 60:
        return False

    # çŸ­ã™ãã‚‹
    if len(id_str) < 30:
        return False

    # Access Keyã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´
    if ACCESS_KEY_PATTERN.search(id_str):
        return False

    # é™¤å¤–ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹
    if id_str in EXCLUDE_IDS:
        return False

    return True


def extract_spreadsheet_ids_from_file(file_path: Path) -> List[Tuple[str, str]]:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Spreadsheet IDã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º

    Returns:
        List of (spreadsheet_id, context_line)
    """
    results = []

    try:
        content = file_path.read_text(encoding='utf-8')
        lines = content.split('\n')

        for i, line in enumerate(lines):
            matches = SPREADSHEET_ID_PATTERN.findall(line)

            for match in matches:
                if is_valid_spreadsheet_id(match):
                    # å‰å¾Œã®è¡Œã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å–å¾—
                    context_lines = []
                    for j in range(max(0, i-1), min(len(lines), i+2)):
                        context_lines.append(lines[j].strip())
                    context = " | ".join(context_lines)

                    results.append((match, context))

    except Exception as e:
        pass

    return results


def find_project_directory(project_name: str) -> Path:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢"""
    for domain_dir in GAS_PROJECTS_DIR.iterdir():
        if domain_dir.is_dir():
            project_dir = domain_dir / project_name
            if project_dir.exists():
                return project_dir
    return None


def extract_all_spreadsheet_ids():
    """å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰Spreadsheet IDã‚’æŠ½å‡º"""
    results = {}

    for gas_project_name, data_source_key in PROJECT_NAME_MAPPING.items():
        print(f"\n{'='*70}")
        print(f"ğŸ” {gas_project_name} ({data_source_key})")
        print(f"{'='*70}")

        project_dir = find_project_directory(gas_project_name)

        if not project_dir:
            print(f"  âŒ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            results[data_source_key] = None
            continue

        print(f"  ğŸ“ {project_dir}")

        # æ¤œç´¢å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
        target_files = []
        target_files.extend(project_dir.rglob("*.gs"))
        target_files.extend(project_dir.rglob("*.md"))
        target_files.extend(project_dir.rglob("*.json"))

        # Spreadsheet IDã‚’åé›†
        found_ids = {}

        for file_path in target_files:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if '_backup' in str(file_path) or '.git' in str(file_path):
                continue

            ids_with_context = extract_spreadsheet_ids_from_file(file_path)

            for spreadsheet_id, context in ids_with_context:
                if spreadsheet_id not in found_ids:
                    found_ids[spreadsheet_id] = []

                found_ids[spreadsheet_id].append({
                    'file': str(file_path.relative_to(project_dir)),
                    'context': context[:150]  # æœ€åˆã®150æ–‡å­—ã®ã¿
                })

        if found_ids:
            print(f"  âœ… è¦‹ã¤ã‹ã£ãŸSpreadsheet ID: {len(found_ids)}å€‹\n")

            for spreadsheet_id, locations in found_ids.items():
                print(f"    ğŸ“Š {spreadsheet_id}")

                for loc in locations[:2]:  # æœ€åˆã®2ç®‡æ‰€ã®ã¿è¡¨ç¤º
                    print(f"       - {loc['file']}")
                    print(f"         {loc['context']}")

                if len(locations) > 2:
                    print(f"       ... ä»– {len(locations) - 2}ç®‡æ‰€")
                print()

            # æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„IDã‚’é¸æŠï¼ˆæœ€ã‚‚å¤šãå‡ºç¾ã™ã‚‹IDï¼‰
            most_common_id = max(found_ids.keys(), key=lambda k: len(found_ids[k]))
            results[data_source_key] = most_common_id
            print(f"  âœ¨ æ¨å¥¨ID: {most_common_id}")

        else:
            print(f"  âš ï¸ Spreadsheet IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            results[data_source_key] = None

    return results


def main():
    print("="*70)
    print("GASãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰è©³ç´°ã«Spreadsheet IDã‚’æŠ½å‡º")
    print("="*70)

    results = extract_all_spreadsheet_ids()

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "="*70)
    print("ğŸ“Š æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼")
    print("="*70)

    found_count = sum(1 for v in results.values() if v)
    total_count = len(results)

    print(f"\nâœ… è¦‹ã¤ã‹ã£ãŸ: {found_count} / {total_count}")
    print(f"âŒ è¦‹ã¤ã‹ã‚‰ãªã„: {total_count - found_count} / {total_count}\n")

    print("ã€æ¨å¥¨Spreadsheet IDã€‘")
    for data_source_key, spreadsheet_id in results.items():
        status = "âœ…" if spreadsheet_id else "âŒ"
        print(f"  {status} {data_source_key:20s} : {spreadsheet_id or 'æœªè¨­å®š'}")

    # JSONå‡ºåŠ›
    import json
    output_file = Path(__file__).parent / "extracted_spreadsheet_ids.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. extracted_spreadsheet_ids.json ã‚’ç¢ºèª")
    print("2. æ­£ã—ã„IDã‚’data_sources.jsonã«ã‚³ãƒ”ãƒ¼")
    print("3. python scripts/vectorize_existing_data.py --list-sources ã§ç¢ºèª")


if __name__ == "__main__":
    main()
