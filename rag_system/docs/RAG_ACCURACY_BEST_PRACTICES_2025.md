# RAGç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ 2025å¹´ç‰ˆ

> **Document Version:** 1.0.0
> **ä½œæˆæ—¥:** 2025-10-27
> **èª¿æŸ»å¯¾è±¡:** Webæ¤œç´¢15ä»¶ + GitHubå®Ÿè£…5ä»¶ + å­¦è¡“è«–æ–‡2ä»¶
> **å¯¾è±¡åˆ†é‡:** åŒ»ç™‚ãƒ»ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢RAGã‚·ã‚¹ãƒ†ãƒ 
> **ç›®çš„:** æœ€æ–°ã®RAGç²¾åº¦å‘ä¸ŠæŠ€è¡“ã‚’çµ±åˆã—ã€å®Ÿè£…å¯èƒ½ãªãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’æä¾›

---

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

### ä¸»è¦ãªç™ºè¦‹

2025å¹´ã®æœ€æ–°èª¿æŸ»ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®RAGç²¾åº¦å‘ä¸ŠæŠ€è¡“ãŒå®Ÿè¨¼ã•ã‚Œã¾ã—ãŸï¼š

| æŠ€è¡“ | ç²¾åº¦æ”¹å–„ | å®Ÿè£…é›£æ˜“åº¦ | ã‚³ã‚¹ãƒˆå½±éŸ¿ | æ¨å¥¨åº¦ |
|------|---------|-----------|----------|--------|
| **Contextual Retrieval** | **+67%** | ä¸­ | ä½ ($1.02/M tokens) | â­â­â­â­â­ |
| **â­ Vertex AI Ranking API** | **State-of-the-art** | **ä½** | **æ¥µä½ ($0.50/æœˆ)** | **â­â­â­â­â­** |
| **Hybrid Search (BM25+Dense+Reranking)** | +30-50% | ä¸­ | ä½ ($0.50/æœˆ) | â­â­â­â­â­ |
| **Query Expansion (Multi-Query)** | +22% NDCG@3 | ä½ | ä½ | â­â­â­â­ |
| **Semantic Chunking** | +40-60% context | ä¸­ | ç„¡æ–™ | â­â­â­â­ |
| **Cross-Encoder Reranking** | +18-22% | ä¸­ | ä¸­ ($5/æœˆ) | â­â­â­â­ |
| **HyDE (Hypothetical Docs)** | +50-80% (è¤‡é›‘ã‚¯ã‚¨ãƒª) | ä¸­ | ä½ | â­â­â­ |
| **Domain Fine-tuning** | +35% | é«˜ | é«˜ | â­â­â­ |

> ğŸ†• **2025å¹´10æœˆã®æœ€æ–°ç™ºè¦‹**: Google Cloudã®Vertex AI Ranking APIã¯ã€ã‚³ã‚¹ãƒˆãƒ»é€Ÿåº¦ãƒ»ç²¾åº¦ã®ã™ã¹ã¦ã§ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ—ãƒªã«æœ€é©ã€‚

### åŒ»ç™‚RAGç‰¹æœ‰ã®æˆæœ

- **GPT-4ç²¾åº¦**: 73.44% â†’ **79.97%** (+6.53%)
- **GPT-3.5ç²¾åº¦**: 60.69% â†’ **71.57%** (+10.88%)
- **MedRAG**: æœ€å¤§ **+18%** ã®ç²¾åº¦å‘ä¸Š
- **Hallucinationå‰Šæ¸›**: **42-96%** (è¤‡æ•°æŠ€è¡“ã®çµ„ã¿åˆã‚ã›)

---

## 1. RAGç²¾åº¦å‘ä¸Šã®å…¨ä½“æˆ¦ç•¥

### 1.1 æœ€æ–°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

#### SELF-RAG (Self-Reflective RAG)
**æ¦‚å¿µ**: è‡ªå·±åçœãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§å‹•çš„ã«æƒ…å ±å–å¾—ã‚’åˆ¤æ–­

**å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆ**:
- æ¤œç´¢ã™ã¹ãã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å‹•çš„åˆ¤æ–­
- ãƒ‡ãƒ¼ã‚¿é–¢é€£æ€§ã®è‡ªå‹•è©•ä¾¡
- äº‹å®Ÿç²¾åº¦ã®å‘ä¸Šã«ç‰¹åŒ–

**å‚è€ƒ**: The 2025 Guide to RAG (EdenAI)

---

#### CRAG (Corrective RAG)
**æ¦‚å¿µ**: è»½é‡ãªå–å¾—è©•ä¾¡å™¨ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªã‚’è©•ä¾¡

**å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆ**:
- ä½å“è³ªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œå‡º
- å¿…è¦æ™‚ã«å¤§è¦æ¨¡Webæ¤œç´¢ã‚’çµ±åˆ
- ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ

**å‚è€ƒ**: The 2025 Guide to RAG (EdenAI)

---

#### i-MedRAG (Iterative Medical RAG)
**æ¦‚å¿µ**: åå¾©çš„ãªãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚¯ã‚¨ãƒªã§æ®µéšçš„ã«æƒ…å ±å–å¾—

**ç²¾åº¦**: MedQA datasetã§ **69.68%**

**å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆ**:
- åˆå›ã‚¯ã‚¨ãƒªã§ä¸è¶³æƒ…å ±ã‚’ç‰¹å®š
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ç”Ÿæˆ
- è¤‡æ•°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®æ®µéšçš„æƒ…å ±åé›†

**å‚è€ƒ**: GitHub - Teddy-XiongGZ/MedRAG

---

### 1.2 å®Ÿè£…å„ªå…ˆé †ä½

#### Phase 1: åŸºç›¤å¼·åŒ–ï¼ˆå³æ™‚å®Ÿè£…æ¨å¥¨ï¼‰
1. âœ… **Hybrid Search** (BM25 + Dense + Cross-Encoder)
2. âœ… **Semantic Chunking** (1500-2000ãƒˆãƒ¼ã‚¯ãƒ³)
3. âœ… **Multi-Query Expansion**
4. âœ… **Contextual Retrieval**

#### Phase 2: é«˜åº¦ãªæœ€é©åŒ–ï¼ˆ3ãƒ¶æœˆä»¥å†…ï¼‰
5. â³ **HyDE (è¤‡é›‘ã‚¯ã‚¨ãƒªç”¨)**
6. â³ **Domain-specific Fine-tuning**
7. â³ **Multi-stage Verification**
8. â³ **Active Hallucination Detection**

#### Phase 3: ç¶™ç¶šçš„æ”¹å–„ï¼ˆ6ãƒ¶æœˆä»¥å†…ï¼‰
9. â³ **Reinforcement Learning from Human Feedback (RLHF)**
10. â³ **Automated Fact-checking Pipeline**
11. â³ **Context Caching**
12. â³ **Multi-modal RAG**

---

## 2. Hybrid Searchå®Ÿè£…æˆ¦ç•¥

### 2.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 0: Query Preprocessing                â”‚
â”‚  - Medical Term Extraction                               â”‚
â”‚  - Synonym Expansion                                     â”‚
â”‚  - Multi-Query Generation (optional)                     â”‚
â”‚  - HyDE Document Generation (optional)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: BM25   â”‚  â”‚ Stage 2: Dense       â”‚
â”‚  Keyword Search  â”‚  â”‚ Vector Retrieval     â”‚
â”‚  Top 100-200     â”‚  â”‚ Top 100-200          â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Stage 3: Fusion          â”‚
    â”‚  - RRF (k=60) or          â”‚
    â”‚  - Weighted Scoring       â”‚
    â”‚  Top 50-100               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Stage 4: Cross-Encoder   â”‚
    â”‚  Reranking                â”‚
    â”‚  Top 10-20                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Stage 5: Validation      â”‚
    â”‚  - Relevance Check        â”‚
    â”‚  - Hallucination Detectionâ”‚
    â”‚  - Alternative Suggestionsâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å®Ÿè£…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

#### BM25è¨­å®š
```python
BM25_CONFIG = {
    'k1': 1.5,              # Term Frequencyé£½å’Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    'b': 0.75,              # Lengthæ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    'top_k': 100,           # åˆæœŸå€™è£œæ•°
    'min_score': 0.0        # æœ€å°ã‚¹ã‚³ã‚¢é–¾å€¤
}
```

**æ¨å¥¨è¨­å®šã®æ ¹æ‹ **:
- k1=1.5: æ¨™æº–çš„ãªè¨­å®šã€åŒ»ç™‚æ–‡æ›¸ã§å®Ÿè¨¼æ¸ˆã¿
- b=0.75: æ–‡æ›¸é•·ã«ã‚ˆã‚‹æ­£è¦åŒ–ã‚’é©åº¦ã«é©ç”¨
- Top 100: å†ç¾ç‡ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒãƒ©ãƒ³ã‚¹

**å‚è€ƒ**: Hybrid Search Revamped - Qdrant

---

#### Dense Retrievalè¨­å®š
```python
DENSE_CONFIG = {
    'model': 'sentence-transformers/all-MiniLM-L6-v2',  # æ±ç”¨
    # 'model': 'microsoft/BiomedNLP-PubMedBERT-base',  # åŒ»ç™‚ç‰¹åŒ–
    'dimension': 384,       # all-MiniLM-L6-v2
    # 'dimension': 768,     # PubMedBERT
    'metric': 'cosine',     # ã¾ãŸã¯ 'dot_product' (æ­£è¦åŒ–æ¸ˆã¿ã®å ´åˆ)
    'top_k': 100,
    'min_score': 0.5        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦é–¾å€¤
}
```

**åŒ»ç™‚åˆ†é‡ã®æ¨å¥¨**:
- **æ±ç”¨ã‚¿ã‚¹ã‚¯**: `all-MiniLM-L6-v2` (é«˜é€Ÿã€è»½é‡)
- **åŒ»ç™‚å°‚é–€**: `BiomedNLP-PubMedBERT-base` (ç²¾åº¦+35%)
- **æœ€é«˜ç²¾åº¦**: `MedCPT` (MedRAGå®Ÿè¨¼æ¸ˆã¿)

**å‚è€ƒ**: GitHub - MedRAG

---

#### Fusionè¨­å®š
```python
# Reciprocal Rank Fusion (RRF)
def rrf_score(rank, k=60):
    """
    RRF Formula: score = 1 / (k + rank)

    Args:
        rank: 1-indexed ranking position
        k: smoothing constant (60æ¨å¥¨)
    """
    return 1.0 / (k + rank)

# Weighted Fusion (ä»£æ›¿æ¡ˆ)
FUSION_WEIGHTS = {
    'bm25': 0.3,
    'dense': 0.7
}
```

**k=60ã®é¸æŠç†ç”±**:
- å®Ÿè¨¼ç ”ç©¶ã§æœ€é©ãªãƒãƒ©ãƒ³ã‚¹
- ãƒˆãƒƒãƒ—å€™è£œã¸ã®éåº¦ãªãƒã‚¤ã‚¢ã‚¹å›é¿
- å¤šæ§˜æ€§ã®ç¢ºä¿

**å‚è€ƒ**: ãƒ•ã‚§ãƒ¼ã‚º2_ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢.md (æ—¢å­˜è³‡æ–™)

---

### 2.3 æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

| æ‰‹æ³• | Precision@10 | Recall@20 | NDCG@5 | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· |
|------|-------------|-----------|--------|----------|
| Dense ã®ã¿ | 68% | 58% | 0.64 | ~0.5ç§’ |
| + BM25 Hybrid | 82% (+14%) | 73% (+15%) | 0.72 (+0.08) | ~0.7ç§’ |
| + RRF Fusion | 85% (+3%) | 88% (+15%) | 0.77 (+0.05) | ~0.8ç§’ |
| **+ Cross-Encoder** | **91% (+6%)** | **92% (+4%)** | **0.87 (+0.10)** | **~1.5ç§’** |

**å‚è€ƒ**: è¤‡æ•°ã‚½ãƒ¼ã‚¹çµ±åˆ (EdenAI, Qdrant, æ—¢å­˜è³‡æ–™)

---

## 3. å†æ¤œç´¢ï¼ˆRerankingï¼‰ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 3.1 Cross-Encoderæœ€é©åŒ–

#### ãƒ¢ãƒ‡ãƒ«é¸æŠ

| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | ç²¾åº¦ (NDCG@10) | ç”¨é€” |
|--------|------------|----------|----------------|------|
| `ms-marco-MiniLM-L-2-v2` | 33M | ~50ms | 0.82 | é«˜é€Ÿã‚¢ãƒ—ãƒª |
| `ms-marco-MiniLM-L-6-v2` | 22M | ~35ms | 0.80 | ãƒãƒ©ãƒ³ã‚¹å‹ |
| **`mmarco-mMiniLMv2-L12-H384-v1`** | **118M** | **~150ms** | **0.85** | **é«˜ç²¾åº¦** |
| `bge-reranker-v2-m3` | 278M | ~300ms | 0.87 | æœ€é«˜ç²¾åº¦ |

**æ¨å¥¨**: `mmarco-mMiniLMv2-L12-H384-v1`
- ç²¾åº¦ã¨é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹
- å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªå«ã‚€ï¼‰
- åŒ»ç™‚æ–‡æ›¸ã§å®Ÿè¨¼æ¸ˆã¿

**å‚è€ƒ**: Ultimate Guide to Reranking (ZeroEntropy), The aRt of RAG Part 3

---

#### å€™è£œæ•°ã®æœ€é©åŒ–

```python
RERANKING_CANDIDATES = {
    'min': 20,              # æœ€å°å€™è£œæ•°ï¼ˆã“ã‚Œä»¥ä¸‹ã¯åŠ¹æœè–„ï¼‰
    'optimal': 50,          # æœ€é©ï¼ˆé€Ÿåº¦ã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
    'max': 100,             # æœ€å¤§ï¼ˆã“ã‚Œä»¥ä¸Šã¯åŠ¹æœãŒãƒ—ãƒ©ãƒˆãƒ¼ï¼‰
    'final_k': 10           # æœ€çµ‚è¿”å´æ•°
}
```

**ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ¨å¥¨**:
- **20å€™è£œ**: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã€æœ€å°é™
- **50å€™è£œ**: æœ€é©ï¼ˆã»ã¨ã‚“ã©ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
- **75å€™è£œ**: åŒ…æ‹¬çš„æ¤œç´¢
- **100å€™è£œä»¥ä¸Š**: å“è³ªå‘ä¸ŠãŒ2%æœªæº€ã€ã‚³ã‚¹ãƒˆå¢—å¤§

**å‚è€ƒ**: OpenAI Cookbook, NVIDIA Technical Blog

---

#### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–

```python
# GPUä½¿ç”¨æ¨å¥¨æ¡ä»¶
if model_params > 30M and queries_per_sec > 10:
    use_gpu = True
    batch_size = 32
else:
    use_gpu = False
    batch_size = 8
    # é‡å­åŒ–ã§åŠ¹ç‡åŒ–
    model = quantize(model, bits=8)
```

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™**:
- **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: <500ms (Cross-Encoderå‡¦ç†)
- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: >100 queries/sec (GPUä½¿ç”¨æ™‚)
- **ç²¾åº¦**: NDCG@10 > 0.85

**å‚è€ƒ**: Vespa.ai Cross-Encoders Guide

---

### 3.2 LLM-based Reranking vs. Cross-Encoder

| é …ç›® | Cross-Encoder | LLM (GPT-4) |
|-----|---------------|-------------|
| **ç²¾åº¦** | NDCG@10: 0.85 | NDCG@10: 0.90 (+5%) |
| **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | ~150ms | ~4-6ç§’ |
| **ã‚³ã‚¹ãƒˆ** | $5/æœˆ (500ã‚¯ã‚¨ãƒª) | $50/æœˆ (500ã‚¯ã‚¨ãƒª) |
| **ãƒ¦ãƒ¼ã‚¶ãƒ¼é›¢è„±** | ä½ (<3ç§’) | é«˜ (>3ç§’) |
| **å®Ÿè£…è¤‡é›‘åº¦** | ä¸­ | ä½ |
| **æ¨å¥¨ã‚·ãƒŠãƒªã‚ª** | **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ—ãƒª** | ãƒãƒƒãƒå‡¦ç† |

**çµè«–**: Cross-Encoderã‚’æ¡ç”¨
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯3ç§’ä»¥ä¸Šã§é›¢è„±ï¼ˆDatabricksèª¿æŸ»ï¼‰
- 5%ã®ç²¾åº¦å‘ä¸Š vs. 30å€ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å¢—åŠ 
- ã‚³ã‚¹ãƒˆã‚‚10å€

**å‚è€ƒ**: Cross-Encoders vs. LLMs (arXiv:2403.10407)

---

### 3.2.1 â­ æœ€æ–°æ¨å¥¨: Vertex AI Ranking API (2025å¹´10æœˆç™ºè¡¨)

Google CloudãŒBEIRãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§state-of-the-artã‚’é”æˆã—ãŸ**ãƒãƒãƒ¼ã‚¸ãƒ‰Reranking API**ã‚’ç™ºè¡¨ã€‚

#### ä¸»è¦ãªåˆ©ç‚¹

| é …ç›® | Vertex AI Ranking API | Cross-Encoder | LLM (GPT-4) |
|-----|----------------------|---------------|-------------|
| **ç²¾åº¦** | **State-of-the-art (BEIR)** | NDCG@10: 0.85 | NDCG@10: 0.90 |
| **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | **<100ms (æœ€é€Ÿ)** | ~150ms | ~4-6ç§’ |
| **ã‚³ã‚¹ãƒˆ** | **$0.50/æœˆ** (500ã‚¯ã‚¨ãƒª) | $5/æœˆ | $50/æœˆ |
| **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£** | **è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒ«** | GPUç®¡ç†å¿…è¦ | APIåˆ¶é™ã‚ã‚Š |
| **ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†** | **ä¸è¦ (ãƒãƒãƒ¼ã‚¸ãƒ‰)** | GPUè¨­å®šå¿…è¦ | ç°¡æ˜“ |
| **çµ±åˆæ€§** | **Vertex AIãƒã‚¤ãƒ†ã‚£ãƒ–** | ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£… | APIå‘¼ã³å‡ºã— |
| **æ¨å¥¨ã‚·ãƒŠãƒªã‚ª** | **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ—ãƒª (æœ€é©)** | ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è¦ä»¶ | ãƒãƒƒãƒå‡¦ç† |

#### æŠ€è¡“ä»•æ§˜

```python
# Vertex AI Ranking API ä½¿ç”¨ä¾‹
from google.cloud import discoveryengine_v1alpha as discoveryengine

client = discoveryengine.RankServiceClient()

# ãƒ¢ãƒ‡ãƒ«é¸æŠ
MODEL_DEFAULT = "semantic-ranker-default-004"  # æœ€é«˜ç²¾åº¦
MODEL_FAST = "semantic-ranker-fast-004"        # ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å„ªå…ˆ

request = discoveryengine.RankRequest(
    ranking_config=f"projects/{project_id}/locations/{location}/rankingConfigs/default_ranking_config",
    model=MODEL_DEFAULT,
    query=query_text,
    records=[
        discoveryengine.RankingRecord(id=str(i), content=doc)
        for i, doc in enumerate(candidate_documents[:200])  # æœ€å¤§200ä»¶
    ],
    top_n=10
)

response = client.rank(request)
ranked_results = [(r.id, r.score) for r in response.records]
```

#### ä¸»è¦åˆ¶é™

- æœ€å¤§200 records/request
- æœ€å¤§200k tokens/request
- å„recordã¯æœ€å¤§1024 tokens
- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œä¸å¯ (APIä¾å­˜)

#### ã‚³ã‚¹ãƒˆåŠ¹ç‡

**ä¾¡æ ¼**: $1.00 per 1,000 queries (1 query = æœ€å¤§100 documents)

**æ¯”è¼ƒ** (500ã‚¯ã‚¨ãƒª/æœˆ):
- Vertex AI Ranking API: **$0.50/æœˆ** (90%å‰Šæ¸›)
- Cross-Encoder: $5.00/æœˆ
- Cohere Rerank API: $1.00/æœˆ

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

- **ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«**: ç«¶åˆæ¯”ã§2å€é«˜é€Ÿ
- **Fastãƒ¢ãƒ‡ãƒ«**: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«æ¯”ã§3å€é«˜é€Ÿ
- **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ç›®æ¨™**: <100ms (å®Ÿæ¸¬)
- **ãƒ‰ãƒ¡ã‚¤ãƒ³å¯¾å¿œ**: retail, news, finance, **healthcare** ã§å®Ÿè¨¼æ¸ˆã¿

#### çµ±åˆæ–¹æ³•

**ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒãƒ¼ãƒˆ**:
- âœ… Vertex AI RAG Engine
- âœ… LangChain
- âœ… GenKit
- âœ… AlloyDB (`ai.rank()` SQLé–¢æ•°)
- âœ… Elasticsearch

**ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**:
```txt
google-cloud-aiplatform>=1.38.0
google-cloud-discoveryengine>=0.11.0
google-auth>=2.23.0
```

#### æ¨å¥¨äº‹é …

ğŸ¯ **å¼·ãæ¨å¥¨**: Backendå®Ÿè£…é–‹å§‹æ™‚ã«Vertex AI Ranking APIã‚’ç¬¬ä¸€é¸æŠè‚¢ã¨ã—ã¦è©•ä¾¡

**ç†ç”±**:
1. âœ… **ã‚³ã‚¹ãƒˆ**: 90%å‰Šæ¸› ($5 â†’ $0.50)
2. âœ… **é€Ÿåº¦**: æœ€é€Ÿ (<100ms)
3. âœ… **ç²¾åº¦**: State-of-the-art
4. âœ… **é‹ç”¨**: GPUã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†ä¸è¦
5. âœ… **çµ±åˆ**: Vertex AIã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹
6. âš ï¸ **å”¯ä¸€ã®æ¬ ç‚¹**: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œä¸å¯

**è©•ä¾¡åŸºæº–**:
- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å®Ÿæ¸¬: <200msé”æˆç¢ºèª
- ç²¾åº¦æ¤œè¨¼: NDCG@10 >= 0.85ç¶­æŒ
- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è¦ä»¶ã®æœ‰ç„¡ç¢ºèª

**å‚è€ƒ**:
- [Launching Vertex AI Ranking API](https://cloud.google.com/blog/products/ai-machine-learning/launching-our-new-state-of-the-art-vertex-ai-ranking-api)
- [Reranking for Vertex AI RAG Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/retrieval-and-ranking)

---

### 3.3 å®Ÿè£…ä¾‹

```python
from sentence_transformers import CrossEncoder

class OptimizedReranker:
    def __init__(self, model_name='cross-encoder/mmarco-mMiniLMv2-L12-H384-v1'):
        self.model = CrossEncoder(model_name, max_length=512)

    def rerank(self, query: str, documents: List[str], top_k: int = 10):
        """
        Cross-Encoderã§å†é †ä½ä»˜ã‘

        Args:
            query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª
            documents: å€™è£œæ–‡æ›¸ãƒªã‚¹ãƒˆ (50-100æ¨å¥¨)
            top_k: è¿”å´ã™ã‚‹æ–‡æ›¸æ•°

        Returns:
            ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸæ–‡æ›¸ãƒªã‚¹ãƒˆ
        """
        # ã‚¯ã‚¨ãƒªã¨å„æ–‡æ›¸ã®ãƒšã‚¢ã‚’ä½œæˆ
        pairs = [(query, doc) for doc in documents]

        # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
        scores = self.model.predict(pairs, batch_size=32, show_progress_bar=False)

        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        ranked_docs = sorted(
            zip(documents, scores),
            key=lambda x: x[1],
            reverse=True
        )

        return ranked_docs[:top_k]
```

**å‚è€ƒ**: OpenAI Cookbook

---

## 4. Queryæœ€é©åŒ–æŠ€è¡“

### 4.1 Contextual Retrieval (Anthropic)

#### æ¦‚å¿µ

**å•é¡Œ**: å¾“æ¥ã®RAGã§ã¯ã€ãƒãƒ£ãƒ³ã‚¯ãŒå˜ç‹¬ã§å­˜åœ¨ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ï¼ˆã©ã®ä¼æ¥­ã€æœŸé–“ãªã©ï¼‰ãŒæ¬ å¦‚

**è§£æ±ºç­–**: å„ãƒãƒ£ãƒ³ã‚¯ã«ãƒãƒ£ãƒ³ã‚¯å›ºæœ‰ã®èª¬æ˜çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰ç½®

```
å…ƒã®ãƒãƒ£ãƒ³ã‚¯:
"å£²ä¸Šé«˜ã¯å‰å¹´æ¯”20%å¢—åŠ ã—ãŸã€‚"

Contextual Chunk:
"ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘ã“ã®æƒ…å ±ã¯ã€æ ªå¼ä¼šç¤¾Fractal Groupã®2024å¹´ç¬¬3å››åŠæœŸæ±ºç®—å ±å‘Šæ›¸ã‹ã‚‰ã®ã‚‚ã®ã§ã™ã€‚
å£²ä¸Šé«˜ã¯å‰å¹´æ¯”20%å¢—åŠ ã—ãŸã€‚"
```

#### å®Ÿè£…

```python
def add_contextual_info(chunk: str, document_metadata: dict, llm_client):
    """
    ãƒãƒ£ãƒ³ã‚¯ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
    """
    prompt = f"""
    æ–‡æ›¸å…¨ä½“: {document_metadata['title']}
    ä½œæˆæ—¥: {document_metadata['date']}
    ã‚«ãƒ†ã‚´ãƒª: {document_metadata['category']}

    ä»¥ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã«ã€ç°¡æ½”ãª1-2æ–‡ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„:

    ãƒãƒ£ãƒ³ã‚¯: {chunk}

    ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
    ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘<èª¬æ˜>
    {chunk}
    """

    return llm_client.generate(prompt, max_tokens=150)
```

#### æ€§èƒ½æ”¹å–„

| æ‰‹æ³• | Top-20 å¤±æ•—ç‡ | æ”¹å–„ç‡ |
|------|--------------|--------|
| ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | 5.7% | - |
| Contextual Embeddings | 3.7% | **-35%** |
| + Contextual BM25 | 2.9% | **-49%** |
| **+ Reranking** | **1.9%** | **-67%** |

**ã‚³ã‚¹ãƒˆ**: $1.02 / 1M document tokens (Prompt Cachingä½¿ç”¨)

**å‚è€ƒ**: Anthropic - Contextual Retrieval

---

### 4.2 Query Expansion

#### Multi-Query Generation

```python
def generate_multi_queries(query: str, num_variations: int = 4):
    """
    LLMã§è¤‡æ•°ã®é¡ä¼¼ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
    """
    prompt = f"""
    å…ƒã®ã‚¯ã‚¨ãƒª: "{query}"

    ä¸Šè¨˜ã®ã‚¯ã‚¨ãƒªã‚’{num_variations}å€‹ã®ç•°ãªã‚‹æ¤œç´¢ã‚¯ã‚¨ãƒªã«å±•é–‹ã—ã¦ãã ã•ã„ã€‚

    è¦ä»¶:
    - ç•°ãªã‚‹è¡¨ç¾ã‚’ä½¿ç”¨
    - ç•°ãªã‚‹å…·ä½“æ€§ãƒ¬ãƒ™ãƒ«
    - ç•°ãªã‚‹å´é¢ã‚’ã‚«ãƒãƒ¼

    JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„:
    {{"queries": ["ã‚¯ã‚¨ãƒª1", "ã‚¯ã‚¨ãƒª2", "ã‚¯ã‚¨ãƒª3", "ã‚¯ã‚¨ãƒª4"]}}
    """

    response = llm_client.generate(prompt, temperature=0.8)
    return json.loads(response)['queries']
```

**æ€§èƒ½æ”¹å–„**: +22 NDCG@3 (Microsoftç ”ç©¶)

**å‚è€ƒ**: Microsoft - Query Rewriting

---

#### HyDE (Hypothetical Document Embeddings)

```python
def generate_hypothetical_doc(query: str):
    """
    ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹ä»®æƒ³çš„ãªå›ç­”æ–‡æ›¸ã‚’ç”Ÿæˆ
    """
    prompt = f"""
    è³ªå•: {query}

    ä¸Šè¨˜ã®è³ªå•ã«å¯¾ã™ã‚‹ç†æƒ³çš„ãªå›ç­”æ–‡æ›¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

    è¦ä»¶:
    - 1500-2000æ–‡å­—
    - å…·ä½“çš„ã§è©³ç´°
    - åŒ»ç™‚å°‚é–€ç”¨èªã‚’é©åˆ‡ã«ä½¿ç”¨
    - æ–‡æ›¸å½¢å¼ï¼ˆè³ªå•å½¢å¼ã§ã¯ãªã„ï¼‰
    """

    hypothetical_doc = llm_client.generate(prompt, temperature=0.7, max_tokens=800)

    # ä»®æƒ³æ–‡æ›¸ã‚’åŸ‹ã‚è¾¼ã¿ã€å®Ÿéš›ã®æ–‡æ›¸ã‚’æ¤œç´¢
    embedding = embed(hypothetical_doc)
    return vector_search(embedding, top_k=50)
```

**æ€§èƒ½æ”¹å–„**: +50-80% (è¤‡é›‘ã‚¯ã‚¨ãƒª)

**å‚è€ƒ**: Advanced RAG 06 (Medium)

---

### 4.3 å®Ÿè£…æ¨å¥¨

| æŠ€è¡“ | é©ç”¨ã‚·ãƒŠãƒªã‚ª | å®Ÿè£…é›£æ˜“åº¦ | åŠ¹æœ |
|------|-------------|-----------|------|
| **Multi-Query** | å…¨ã‚¯ã‚¨ãƒª | ä½ | +22% NDCG |
| **HyDE** | è¤‡é›‘ã‚¯ã‚¨ãƒªï¼ˆåŒ»ç™‚å°‚é–€ç”¨èªå¤šæ•°ï¼‰ | ä¸­ | +50-80% |
| **Query Rewriting** | æ›–æ˜§ãªã‚¯ã‚¨ãƒª | ä½ | +15-20% |
| **Contextual Retrieval** | å…¨ãƒãƒ£ãƒ³ã‚¯ | ä¸­ | -67% å¤±æ•—ç‡ |

**æ¨å¥¨å®Ÿè£…é †åº**:
1. Multi-Query (å³æ™‚)
2. Contextual Retrieval (1é€±é–“ä»¥å†…)
3. HyDE (2é€±é–“ä»¥å†…ã€è¤‡é›‘ã‚¯ã‚¨ãƒªç”¨)

---

## 5. ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥

### 5.1 æœ€é©ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º

#### 2025å¹´ã®æ¨å¥¨å€¤

| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ— | ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º | ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ— | æ ¹æ‹  |
|------------------|-------------|------------|------|
| **åŒ»ç™‚è¨˜éŒ²ï¼ˆçŸ­æ–‡ï¼‰** | 256-512 tokens | 50-100 tokens (10-20%) | äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã®ã‚¯ã‚¨ãƒªã«æœ€é© |
| **çœ‹è­·è¨ˆç”»æ›¸** | 512-1024 tokens | 100-200 tokens (15-20%) | ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿æŒãŒé‡è¦ |
| **åŒ»å­¦è«–æ–‡** | 1024-1536 tokens | 150-300 tokens (15%) | åŒ…æ‹¬çš„ãªç†è§£ãŒå¿…è¦ |
| **ä¸€èˆ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** | 512 tokens | 100 tokens (20%) | ãƒãƒ©ãƒ³ã‚¹å‹ |

**NVIDIAç ”ç©¶çµæœ**:
- 128 tokens: ãƒ•ã‚¡ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹ã€ç²¾åº¦é«˜ã„ãŒæ–‡è„ˆä¸è¶³
- 512-1024 tokens: **æœ€é©** (FinanceBench, RAGBattle)
- 2048 tokens: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹

**å‚è€ƒ**: NVIDIA - Chunking Strategy, Databricks Guide

---

### 5.2 Semantic Chunking

#### å¾“æ¥ã®å›ºå®šé•·ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå•é¡Œï¼‰
```python
# å•é¡Œã®ã‚ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
chunks = split_text(document, chunk_size=1000, overlap=200)
# â†’ æ®µè½é€”ä¸­ã§åˆ†å‰²
# â†’ æ–‡è„ˆã®é€£ç¶šæ€§å–ªå¤±
# â†’ ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ç®‡æ¡æ›¸ããŒæ–­ç‰‡åŒ–
```

#### Semantic Chunkingï¼ˆæ¨å¥¨ï¼‰
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãªåˆ†å‰²
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1500,
    chunk_overlap=200,
    separators=[
        "\n\n",    # æ®µè½
        "\n",      # æ”¹è¡Œ
        "ã€‚",      # å¥ç‚¹
        ".",       # ãƒ”ãƒªã‚ªãƒ‰
        " ",       # ç©ºç™½
        ""         # æ–‡å­—å˜ä½ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
    ],
    length_function=len,
)

chunks = text_splitter.split_text(document)
```

**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„**:
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é€£ç¶šæ€§: **+40-60%**
- å›ç­”ã®è‡ªç„¶ã•: **+30%**
- ãƒãƒ£ãƒ³ã‚¯é–“ã®æ„å‘³çš„é‡è¤‡: **-50%**

**å‚è€ƒ**: Semantic Chunking for RAG (Multimodal.dev)

---

### 5.3 Context-Aware Chunking

#### Late Chunking

```python
def late_chunking(document: str, model):
    """
    ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼å…¨ä½“ã‚’é€šã—ãŸå¾Œã«åˆ†å‰²
    """
    # 1. æ–‡æ›¸å…¨ä½“ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
    tokens = model.tokenize(document)

    # 2. ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼å±¤ã‚’é€šã™
    embeddings = model.encode_tokens(tokens)  # å…¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿æŒ

    # 3. ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ï¼ˆåŸ‹ã‚è¾¼ã¿ç”Ÿæˆå¾Œï¼‰
    chunk_embeddings = split_embeddings(embeddings, chunk_size=512)

    return chunk_embeddings
```

**åˆ©ç‚¹**:
- ãƒ•ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸåŸ‹ã‚è¾¼ã¿
- ãƒãƒ£ãƒ³ã‚¯å¢ƒç•Œã§ã®æƒ…å ±æå¤±å›é¿
- é«˜ç²¾åº¦ãªæ¤œç´¢

**å‚è€ƒ**: RAG_Techniques/semantic_chunking.ipynb (GitHub)

---

### 5.4 åŒ»ç™‚æ–‡æ›¸ç‰¹æœ‰ã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°

```python
MEDICAL_CHUNKING_CONFIG = {
    'care_records': {
        'size': 512,
        'overlap': 100,
        'preserve': ['vital_signs', 'medications', 'assessments']
    },
    'care_plans': {
        'size': 1024,
        'overlap': 200,
        'preserve': ['goals', 'interventions', 'evaluations']
    },
    'clinical_notes': {
        'size': 768,
        'overlap': 150,
        'preserve': ['chief_complaint', 'diagnosis', 'treatment']
    }
}
```

**å®Ÿè£…æ¨å¥¨**:
1. æ§‹é€ åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆãƒã‚¤ã‚¿ãƒ«ã‚µã‚¤ãƒ³ç­‰ï¼‰ã¯åˆ†å‰²ã—ãªã„
2. åŒ»ç™‚ç”¨èªã®é€”ä¸­ã§åˆ†å‰²ã—ãªã„
3. æ—¥ä»˜ãƒ»æ™‚åˆ»æƒ…å ±ã‚’å„ãƒãƒ£ãƒ³ã‚¯ã«å«ã‚ã‚‹

---

## 6. è©•ä¾¡æŒ‡æ¨™ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### 6.1 Retrievalè©•ä¾¡æŒ‡æ¨™

#### Precision@K
```python
def precision_at_k(retrieved_docs, relevant_docs, k):
    """
    Top-Kçµæœã®ã†ã¡ã€é–¢é€£æ–‡æ›¸ã®å‰²åˆ
    """
    top_k_docs = retrieved_docs[:k]
    relevant_in_top_k = sum(1 for doc in top_k_docs if doc in relevant_docs)
    return relevant_in_top_k / k
```

**ç›®æ¨™å€¤**: Precision@10 > 85%

---

#### Recall@K
```python
def recall_at_k(retrieved_docs, relevant_docs, k):
    """
    å…¨é–¢é€£æ–‡æ›¸ã®ã†ã¡ã€Top-Kçµæœã«å«ã¾ã‚Œã‚‹å‰²åˆ
    """
    top_k_docs = retrieved_docs[:k]
    relevant_in_top_k = sum(1 for doc in top_k_docs if doc in relevant_docs)
    return relevant_in_top_k / len(relevant_docs)
```

**ç›®æ¨™å€¤**: Recall@20 > 92%

---

#### NDCG (Normalized Discounted Cumulative Gain)
```python
import numpy as np

def ndcg_at_k(relevance_scores, k):
    """
    é †ä½ã‚’è€ƒæ…®ã—ãŸè©•ä¾¡æŒ‡æ¨™ï¼ˆä¸Šä½ã»ã©é‡è¦ï¼‰
    """
    def dcg(scores):
        return sum(score / np.log2(i + 2) for i, score in enumerate(scores[:k]))

    actual_dcg = dcg(relevance_scores)
    ideal_dcg = dcg(sorted(relevance_scores, reverse=True))

    return actual_dcg / ideal_dcg if ideal_dcg > 0 else 0.0
```

**ç›®æ¨™å€¤**: NDCG@5 > 0.75

**å‚è€ƒ**: RAG Evaluation Metrics (FutureAGI)

---

### 6.2 Generationè©•ä¾¡æŒ‡æ¨™

#### Faithfulness (å¿ å®Ÿæ€§)
```python
def calculate_faithfulness(generated_answer, retrieved_context):
    """
    ç”Ÿæˆã•ã‚ŒãŸå›ç­”ãŒå–å¾—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿ å®Ÿã‹
    """
    # å›ç­”å†…ã®äº‹å®Ÿçš„ä¸»å¼µã‚’æŠ½å‡º
    claims = extract_claims(generated_answer)

    # å„ä¸»å¼µãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§è£ä»˜ã‘ã‚‰ã‚Œã‚‹ã‹æ¤œè¨¼
    supported_claims = sum(
        1 for claim in claims if is_supported(claim, retrieved_context)
    )

    return supported_claims / len(claims)
```

**ç›®æ¨™å€¤**: Faithfulness > 0.90 (åŒ»ç™‚åˆ†é‡)

**Hallucination Rate**: 1 - Faithfulness < 0.10

---

#### Answer Relevance (å›ç­”é–¢é€£æ€§)
```python
def answer_relevance(query, generated_answer):
    """
    ç”Ÿæˆã•ã‚ŒãŸå›ç­”ãŒã‚¯ã‚¨ãƒªã«é–¢é€£ã—ã¦ã„ã‚‹ã‹
    """
    # ã‚¯ã‚¨ãƒªã¨å›ç­”ã®æ„å‘³çš„é¡ä¼¼åº¦
    query_embedding = embed(query)
    answer_embedding = embed(generated_answer)

    similarity = cosine_similarity(query_embedding, answer_embedding)
    return similarity
```

**ç›®æ¨™å€¤**: Answer Relevance > 0.85

**å‚è€ƒ**: RAGAS Framework

---

### 6.3 RAGASçµ±åˆè©•ä¾¡

```python
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)

# è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
eval_dataset = {
    'question': ["ãƒãƒ«ãƒ¼ãƒ³ã‚«ãƒ†ãƒ¼ãƒ†ãƒ«ã®ç®¡ç†æ–¹æ³•ã¯ï¼Ÿ", ...],
    'answer': ["è†€èƒ±ç•™ç½®ã‚«ãƒ†ãƒ¼ãƒ†ãƒ«ã®ç®¡ç†ã§ã¯...", ...],
    'contexts': [[retrieved_doc1, retrieved_doc2], ...],
    'ground_truths': [["æ­£è§£å›ç­”1"], ...]
}

# RAGASã‚¹ã‚³ã‚¢è¨ˆç®—
results = evaluate(
    eval_dataset,
    metrics=[
        faithfulness,           # å¿ å®Ÿæ€§
        answer_relevancy,       # å›ç­”é–¢é€£æ€§
        context_precision,      # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç²¾åº¦
        context_recall          # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†ç¾ç‡
    ]
)

print(f"Overall RAGAS Score: {results['ragas_score']:.2f}")
```

**ç›®æ¨™RAGAS Score**: > 0.80

**å‚è€ƒ**: Weaviate - RAG Evaluation

---

### 6.4 æœ¬ç•ªç’°å¢ƒãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

#### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
MONITORING_METRICS = {
    # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
    'retrieval_latency_p50': '<300ms',
    'retrieval_latency_p95': '<500ms',
    'reranking_latency_p50': '<150ms',
    'reranking_latency_p95': '<300ms',
    'generation_latency_p50': '<1000ms',
    'generation_latency_p95': '<2000ms',
    'total_latency_p95': '<3000ms',  # ãƒ¦ãƒ¼ã‚¶ãƒ¼é›¢è„±é–¾å€¤

    # ç²¾åº¦
    'precision_at_10': '>0.85',
    'ndcg_at_5': '>0.75',
    'faithfulness': '>0.90',

    # ã‚·ã‚¹ãƒ†ãƒ 
    'error_rate': '<5%',
    'cache_hit_rate': '>60%',
    'queries_per_second': 'monitor',

    # ãƒ“ã‚¸ãƒã‚¹
    'user_satisfaction': '>4.0/5.0',
    'query_abandonment_rate': '<15%'
}
```

#### ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

```python
ALERTS = {
    'critical': {
        'latency_p95': '>5000ms',     # å³æ™‚å¯¾å¿œ
        'error_rate': '>10%',          # å³æ™‚å¯¾å¿œ
        'faithfulness': '<0.80'        # å³æ™‚å¯¾å¿œ
    },
    'warning': {
        'latency_p95': '>3000ms',     # 24æ™‚é–“ä»¥å†…
        'error_rate': '>5%',           # 24æ™‚é–“ä»¥å†…
        'precision_at_10': '<0.80'     # 1é€±é–“ä»¥å†…
    }
}
```

**å‚è€ƒ**: Best Practices for Monitoring RAG (WhyLabs)

---

## 7. Hallucinationå¯¾ç­–

### 7.1 ä¸»è¦ãªå¤±æ•—ãƒ¢ãƒ¼ãƒ‰

#### Retrieval Failureï¼ˆå–å¾—å¤±æ•—ï¼‰
1. **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å•é¡Œ**: ä¸æ­£ç¢ºã€å¤ã„ã€ä¸å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿
2. **ã‚¯ã‚¨ãƒªã®æ›–æ˜§æ€§**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªãŒä¸æ˜ç¢º
3. **Retrieveråˆ¶é™**: é©åˆ‡ãªæ–‡æ›¸ã‚’å–å¾—ã§ããªã„
4. **æˆ¦ç•¥å•é¡Œ**: æ¤œç´¢æˆ¦ç•¥ãŒä¸é©åˆ‡

#### Generation Deficiencyï¼ˆç”Ÿæˆä¸è¶³ï¼‰
1. **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ã‚º**: ç„¡é–¢é€£æƒ…å ±ãŒæ··å…¥
2. **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç«¶åˆ**: çŸ›ç›¾ã™ã‚‹æƒ…å ±
3. **Middle Curse**: é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¸­é–“ã‚’ç„¡è¦–
4. **ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå•é¡Œ**: ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã®ãƒŸã‚¹ãƒãƒƒãƒ
5. **èƒ½åŠ›å¢ƒç•Œ**: LLMã®çŸ¥è­˜é™ç•Œ

**å‚è€ƒ**: Hallucination Mitigation (MDPI)

---

### 7.2 å¯¾ç­–æˆ¦ç•¥

#### 1. Enhanced Retrieval

```python
class EnhancedRetrieval:
    def retrieve(self, query):
        # ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆ
        expanded_queries = query_expansion(query)

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
        bm25_results = bm25_search(expanded_queries)
        dense_results = vector_search(expanded_queries)

        # Fusion
        fused_results = rrf_fusion(bm25_results, dense_results)

        # Reranking
        reranked_results = cross_encoder_rerank(query, fused_results)

        return reranked_results[:10]
```

**å‰Šæ¸›åŠ¹æœ**: -42-68% hallucinations

---

#### 2. Span-level Verification

```python
def verify_claims(generated_answer, retrieved_context):
    """
    ç”Ÿæˆã•ã‚ŒãŸå„ä¸»å¼µã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§æ¤œè¨¼
    """
    claims = extract_claims(generated_answer)
    verified_claims = []

    for claim in claims:
        # å„ä¸»å¼µã®è£ä»˜ã‘ã‚’æ¤œç´¢
        evidence = find_evidence(claim, retrieved_context)

        if evidence:
            verified_claims.append({
                'claim': claim,
                'verified': True,
                'evidence': evidence
            })
        else:
            # è£ä»˜ã‘ã®ãªã„ä¸»å¼µã‚’è­¦å‘Š
            verified_claims.append({
                'claim': claim,
                'verified': False,
                'warning': 'ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§è£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã¾ã›ã‚“'
            })

    return verified_claims
```

**å‰Šæ¸›åŠ¹æœ**: -70-80% (ã‚¹ãƒ‘ãƒ³ãƒ¬ãƒ™ãƒ«æ¤œè¨¼)

**å‚è€ƒ**: Multi-Stage Verification (arXiv:2507.20136)

---

#### 3. Cross-Layer Attention Probing (CLAP)

```python
class HallucinationDetector:
    def __init__(self, model):
        self.model = model
        self.classifier = train_lightweight_classifier(model.activations)

    def detect_hallucination(self, generated_text):
        """
        ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨æ´»æ€§åŒ–ã‹ã‚‰å¹»è¦šã‚’æ¤œå‡º
        """
        activations = self.model.get_activations(generated_text)
        hallucination_prob = self.classifier.predict(activations)

        return hallucination_prob > 0.5
```

**å‰Šæ¸›åŠ¹æœ**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡ºã€ç²¾åº¦ ~85%

---

#### 4. Uncertainty-aware Generation

```python
def generate_with_uncertainty(query, context, model):
    """
    ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸç”Ÿæˆ
    """
    response = model.generate(
        prompt=f"Context: {context}\nQuery: {query}",
        temperature=0.1,  # ä½æ¸©åº¦ã§ç¢ºå®šçš„ã«
        return_uncertainty=True
    )

    if response.uncertainty > 0.7:
        # ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„å ´åˆ
        return {
            'answer': response.text,
            'warning': 'å›ç­”ã®ç¢ºå®Ÿæ€§ãŒä½ã„ãŸã‚ã€å°‚é–€å®¶ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚',
            'confidence': 1 - response.uncertainty
        }

    return {
        'answer': response.text,
        'confidence': 1 - response.uncertainty
    }
```

---

### 7.3 çµ±åˆçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

```python
class RobustRAGPipeline:
    def __init__(self):
        self.retriever = EnhancedRetrieval()
        self.reranker = CrossEncoderReranker()
        self.generator = UncertaintyAwareGenerator()
        self.verifier = ClaimVerifier()
        self.detector = HallucinationDetector()

    def query(self, user_query):
        # 1. å¼·åŒ–ã•ã‚ŒãŸæ¤œç´¢
        retrieved_docs = self.retriever.retrieve(user_query)

        # 2. å†é †ä½ä»˜ã‘
        reranked_docs = self.reranker.rerank(user_query, retrieved_docs)

        # 3. ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸç”Ÿæˆ
        response = self.generator.generate(user_query, reranked_docs)

        # 4. ä¸»å¼µã®æ¤œè¨¼
        verified_claims = self.verifier.verify(response.text, reranked_docs)

        # 5. å¹»è¦šæ¤œå‡º
        has_hallucination = self.detector.detect(response.text)

        # 6. çµ±åˆçµæœ
        return {
            'answer': response.text,
            'confidence': response.confidence,
            'verified_claims': verified_claims,
            'hallucination_detected': has_hallucination,
            'sources': reranked_docs[:3]
        }
```

**çµ±åˆçš„å‰Šæ¸›åŠ¹æœ**: -96% hallucinations (Stanfordç ”ç©¶)

**å‚è€ƒ**: Understanding RAG Part VIII (MachineLearningMastery)

---

## 8. åŒ»ç™‚RAGç‰¹æœ‰ã®è€ƒæ…®äº‹é …

### 8.1 åŒ»ç™‚ã‚³ãƒ¼ãƒ‘ã‚¹ã®æœ€é©åŒ–

#### æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹

| ã‚³ãƒ¼ãƒ‘ã‚¹ | è¦æ¨¡ | ç”¨é€” | ç²¾åº¦è²¢çŒ® |
|---------|------|------|---------|
| **PubMed** | 23.9M abstracts | ä¸€èˆ¬åŒ»å­¦çŸ¥è­˜ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ |
| **StatPearls** | 9.3K documents | è‡¨åºŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ | +8% |
| **åŒ»å­¦æ•™ç§‘æ›¸** | 18 sources | åŸºç¤çŸ¥è­˜ | +5% |
| **çµ„ç¹”å†…è¨˜éŒ²** | 13,500+ records | ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ– | **+15%** |
| **MedCorpçµ±åˆ** | 54.2M snippets | åŒ…æ‹¬çš„ | **+18%** |

**å‚è€ƒ**: GitHub - MedRAG

---

#### åŒ»ç™‚ç”¨èªå‡¦ç†

```python
MEDICAL_TERMS_CONFIG = {
    'synonym_expansion': True,      # é¡ç¾©èªå±•é–‹ï¼ˆå¿…é ˆï¼‰
    'abbreviation_handling': True,  # ç•¥èªå‡¦ç†ï¼ˆå¿…é ˆï¼‰
    'ontology': 'UMLS',            # åŒ»ç™‚ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼
    'language': 'ja',              # æ—¥æœ¬èªåŒ»ç™‚ç”¨èª

    # ä¾‹: "ãƒãƒ«ãƒ¼ãƒ³" â†’ ["è†€èƒ±ç•™ç½®ã‚«ãƒ†ãƒ¼ãƒ†ãƒ«", "å°¿é“ã‚«ãƒ†ãƒ¼ãƒ†ãƒ«", "Foley catheter"]
}
```

**å®Ÿè£…æ¨å¥¨**:
1. UMLSï¼ˆçµ±ä¸€åŒ»ç™‚è¨€èªã‚·ã‚¹ãƒ†ãƒ ï¼‰çµ±åˆ
2. æ—¥æœ¬èªåŒ»ç™‚ç”¨èªè¾æ›¸ï¼ˆMeCabåŒ»ç™‚è¾æ›¸ï¼‰
3. ç•¥èªãƒ»æ­£å¼åç§°ã®åŒæ–¹å‘ãƒãƒƒãƒ”ãƒ³ã‚°

---

### 8.2 è©•ä¾¡åŸºæº–ã®å³æ ¼åŒ–

#### åŒ»ç™‚ç‰¹æœ‰ã®è©•ä¾¡æŒ‡æ¨™

```python
MEDICAL_EVALUATION = {
    'faithfulness': 0.95,           # æ¨™æº–0.90 â†’ åŒ»ç™‚0.95
    'factual_accuracy': 0.95,       # äº‹å®Ÿç²¾åº¦
    'safety_score': 0.98,           # å®‰å…¨æ€§ã‚¹ã‚³ã‚¢
    'clinical_relevance': 0.90,     # è‡¨åºŠçš„é–¢é€£æ€§
    'temporal_accuracy': 0.95,      # æ™‚é–“çš„æ­£ç¢ºæ€§ï¼ˆæœ€æ–°æƒ…å ±ï¼‰
}
```

**è¨±å®¹Hallucination Rate**: <2% (æ¨™æº–<10%)

---

#### Human-in-the-Loopè©•ä¾¡

```python
def medical_rag_evaluation(query, generated_answer, context):
    """
    åŒ»ç™‚å°‚é–€å®¶ã«ã‚ˆã‚‹æ®µéšçš„è©•ä¾¡
    """
    evaluation = {
        'automated_checks': {
            'faithfulness': calculate_faithfulness(generated_answer, context),
            'hallucination_detected': detect_hallucination(generated_answer),
            'clinical_terms_correct': verify_medical_terms(generated_answer)
        },
        'expert_review': {
            'status': 'pending',
            'reviewer': None,
            'score': None
        }
    }

    # è‡ªå‹•ãƒã‚§ãƒƒã‚¯ã§å•é¡ŒãŒã‚ã‚Œã°å³åº§ã«å°‚é–€å®¶ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if (evaluation['automated_checks']['faithfulness'] < 0.95 or
        evaluation['automated_checks']['hallucination_detected']):
        evaluation['expert_review']['status'] = 'urgent'

    return evaluation
```

---

### 8.3 åŒ»ç™‚RAGã®æˆåŠŸäº‹ä¾‹

#### MedRAG Performance

| LLM | Baseline (CoT) | MedRAG | æ”¹å–„ |
|-----|---------------|--------|------|
| GPT-4 | 73.44% | **79.97%** | +6.53% |
| GPT-3.5 | 60.69% | **71.57%** | +10.88% |
| Mixtral | 61.42% | **69.48%** | +8.06% |

**å‚è€ƒ**: GitHub - MedRAG, NVIDIA Medical RAG

---

#### i-MedRAG (Iterative)

```python
class IterativeMedicalRAG:
    def query_with_followup(self, initial_query):
        """
        åå¾©çš„ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚¯ã‚¨ãƒª
        """
        results = []
        current_query = initial_query
        max_iterations = 3

        for i in range(max_iterations):
            # æ¤œç´¢
            docs = self.retrieve(current_query)

            # ç”Ÿæˆ
            answer = self.generate(current_query, docs)
            results.append(answer)

            # ä¸è¶³æƒ…å ±ã®ç‰¹å®š
            missing_info = self.identify_gaps(answer, initial_query)

            if not missing_info:
                break  # ååˆ†ãªæƒ…å ±ãŒå¾—ã‚‰ã‚ŒãŸ

            # ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚¯ã‚¨ãƒªç”Ÿæˆ
            current_query = self.generate_followup_query(
                initial_query,
                missing_info,
                previous_results=results
            )

        # çµ±åˆå›ç­”
        return self.synthesize_answer(results)
```

**ç²¾åº¦**: MedQA dataset ã§ **69.68%**

**å‚è€ƒ**: arXiv - i-MedRAG

---

## 9. å®Ÿè£…å‚è€ƒè³‡æ–™

### 9.1 GitHub ãƒªãƒã‚¸ãƒˆãƒª

#### åŒ»ç™‚RAGå®Ÿè£…

| ãƒªãƒã‚¸ãƒˆãƒª | ä¸»è¦æŠ€è¡“ | ç‰¹å¾´ | Stars |
|-----------|---------|------|-------|
| **[MedRAG](https://github.com/Teddy-XiongGZ/MedRAG)** | Multi-corpus, MedCPT | MIRAGEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€æœ€å¤§+18%ç²¾åº¦ | 600+ |
| **[Medical_ChatBot](https://github.com/joyceannie/Medical_ChatBot)** | PubMedBERT, LangChain | åŒ»ç™‚ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–embedding | 150+ |
| **[rag-healthcare-assistant](https://github.com/RaviKunapareddy/rag-healthcare-assistant)** | Gemini LLM, MedQuAD | Sentence Transformersä½¿ç”¨ | 80+ |
| **[Medical-Chatbot](https://github.com/abhroroy365/Medical-Chatbot)** | Llama2, FAISS | ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚¹ã‚¿ãƒƒã‚¯ | 100+ |

---

#### Hybrid Search + FastAPI

| ãƒªãƒã‚¸ãƒˆãƒª | ä¸»è¦æŠ€è¡“ | ç‰¹å¾´ | Stars |
|-----------|---------|------|-------|
| **[Hybrid-Search-RAG](https://github.com/kolhesamiksha/Hybrid-Search-RAG)** | FastAPI, Async | Query expansion, caching | 200+ |
| **[Hybrid-Search-For-Rag](https://github.com/Syed007Hassan/Hybrid-Search-For-Rag)** | PostgreSQL, PgVector | Async streaming | 120+ |
| **[Azure RAG Sample](https://github.com/Azure-Samples/app-service-rag-openai-ai-search-python)** | Azure AI Search | Hybrid: vector+keyword+semantic | Microsoftå…¬å¼ |

---

### 9.2 å­¦è¡“è«–æ–‡

| è«–æ–‡ | ä¸»è¦è²¢çŒ® | ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ |
|-----|---------|-----------|
| **[arXiv:2501.07391](https://arxiv.org/abs/2501.07391)** | RAGãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ä½“ç³»åŒ– | Query expansion, retrieval stride, multilingual |
| **[arXiv:2403.10407](https://arxiv.org/html/2403.10407v1)** | Cross-Encoder vs. LLMæ¯”è¼ƒ | Cross-Encoderæ¡ç”¨æ ¹æ‹  |
| **[arXiv:2408.00727](https://arxiv.org/html/2408.00727v1)** | i-MedRAG (Iterative Medical RAG) | +15% medical QA accuracy |
| **[arXiv:2507.20136](https://arxiv.org/abs/2507.20136)** | Multi-stage verification | -70% hallucinations |

---

### 9.3 æŠ€è¡“ãƒ–ãƒ­ã‚°ãƒ»ã‚¬ã‚¤ãƒ‰

| ã‚½ãƒ¼ã‚¹ | ãƒˆãƒ”ãƒƒã‚¯ | é‡è¦åº¦ |
|--------|---------|--------|
| **[Anthropic - Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)** | Contextual Embeddings/BM25 | â­â­â­â­â­ |
| **[OpenAI Cookbook - Cross-Encoders](https://cookbook.openai.com/examples/search_reranking_with_cross-encoders)** | Rerankingå®Ÿè£… | â­â­â­â­â­ |
| **[NVIDIA - Chunking Strategy](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses/)** | ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºæœ€é©åŒ– | â­â­â­â­ |
| **[Databricks - Chunking Guide](https://community.databricks.com/t5/technical-blog/the-ultimate-guide-to-chunking-strategies-for-rag-applications/ba-p/113089)** | 11ç¨®é¡ã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ | â­â­â­â­ |
| **[Microsoft - Query Rewriting](https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/raising-the-bar-for-rag-excellence-query-rewriting-and-new-semantic-ranker/4302729)** | Queryæœ€é©åŒ– | â­â­â­â­ |

---

### 9.4 è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

| ãƒ„ãƒ¼ãƒ« | æ©Ÿèƒ½ | æ¨å¥¨åº¦ |
|--------|------|--------|
| **[RAGAS](https://github.com/explodinggradients/ragas)** | RAGçµ±åˆè©•ä¾¡ (Faithfulness, Relevance) | â­â­â­â­â­ |
| **[LangSmith](https://www.langchain.com/langsmith)** | LLMã‚¢ãƒ—ãƒªç›£è¦– | â­â­â­â­â­ |
| **[Athina AI](https://hub.athina.ai/)** | RAGå°‚ç”¨ãƒ†ã‚¹ãƒˆãƒ»ç›£è¦– | â­â­â­â­ |
| **[WhyLabs](https://whylabs.ai/)** | æœ¬ç•ªç’°å¢ƒç›£è¦– | â­â­â­â­ |

---

## 10. æ¨å¥¨å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 1: åŸºç›¤æ§‹ç¯‰ï¼ˆWeek 1-2ï¼‰

#### Week 1: Hybrid Searchå®Ÿè£…
```
âœ… Tasks:
1. BM25 Retrieverå®Ÿè£…
   - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
   - ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
   - Top 100å€™è£œå–å¾—

2. Dense Retrievalå®Ÿè£…
   - Sentence Transformersçµ±åˆ
   - åŒ»ç™‚ç”¨èªembedding
   - Top 100å€™è£œå–å¾—

3. RRF Fusionå®Ÿè£…
   - k=60ã§ã®Reciprocal Rank Fusion
   - Top 50å€™è£œé¸æŠ

4. Cross-Encoder Reranking
   - ms-marco-MiniLM-L-12ãƒ¢ãƒ‡ãƒ«
   - Top 10æœ€çµ‚çµæœ

ğŸ“Š Success Metrics:
- Precision@10 > 0.85
- NDCG@5 > 0.75
- Latency < 2ç§’
```

---

#### Week 2: Semantic Chunking & Contextual Retrieval
```
âœ… Tasks:
1. Semantic Chunkingå°å…¥
   - RecursiveCharacterTextSplitter
   - 1500ãƒˆãƒ¼ã‚¯ãƒ³ã€200ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
   - åŒ»ç™‚ç”¨èªå¢ƒç•Œã®ä¿è­·

2. Contextual Retrievalå®Ÿè£…
   - ãƒãƒ£ãƒ³ã‚¯ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ 
   - Prompt Cachingä½¿ç”¨
   - ã‚³ã‚¹ãƒˆæœ€é©åŒ–

3. åŒ»ç™‚ç”¨èªè¾æ›¸çµ±åˆ
   - UMLS/SNOMED CTæº–æ‹ 
   - é¡ç¾©èªå±•é–‹
   - ç•¥èªå‡¦ç†

ğŸ“Š Success Metrics:
- Context Relevance > 0.90
- å¤±æ•—ç‡ < 3%
- ãƒãƒ£ãƒ³ã‚¯å“è³ªã‚¹ã‚³ã‚¢ > 0.85
```

---

### Phase 2: ç²¾åº¦å‘ä¸Šï¼ˆWeek 3-4ï¼‰

#### Week 3: Queryæœ€é©åŒ–
```
âœ… Tasks:
1. Multi-Query Generation
   - LLMã§4-5å€‹ã®ã‚¯ã‚¨ãƒªç”Ÿæˆ
   - ä¸¦åˆ—æ¤œç´¢
   - çµæœçµ±åˆ

2. HyDEå®Ÿè£…ï¼ˆè¤‡é›‘ã‚¯ã‚¨ãƒªç”¨ï¼‰
   - ä»®æƒ³æ–‡æ›¸ç”Ÿæˆ
   - åŸ‹ã‚è¾¼ã¿æ¤œç´¢
   - å®Ÿæ–‡æ›¸ãƒãƒƒãƒãƒ³ã‚°

3. Query Rewriting
   - æ›–æ˜§ãªã‚¯ã‚¨ãƒªã®æ˜ç¢ºåŒ–
   - åŒ»ç™‚ç”¨èªã¸ã®å¤‰æ›
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„å›³æ¨å®š

ğŸ“Š Success Metrics:
- NDCG@3 +22%
- è¤‡é›‘ã‚¯ã‚¨ãƒªç²¾åº¦ +50%
- ã‚¯ã‚¨ãƒªæ˜ç¢ºæ€§ã‚¹ã‚³ã‚¢ > 0.80
```

---

#### Week 4: è©•ä¾¡ãƒ»ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°åŸºç›¤
```
âœ… Tasks:
1. RAGASãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯çµ±åˆ
   - Faithfulnessè¨ˆç®—
   - Answer Relevanceè¨ˆç®—
   - Context Precision/Recall

2. æœ¬ç•ªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°è¨­å®š
   - LangSmithçµ±åˆ
   - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
   - ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

3. Hallucinationæ¤œå‡º
   - Span-level verification
   - Confidence scoring
   - Warning system

ğŸ“Š Success Metrics:
- RAGAS Score > 0.80
- Faithfulness > 0.95
- Hallucination Rate < 2%
```

---

### Phase 3: åŒ»ç™‚ç‰¹åŒ–æœ€é©åŒ–ï¼ˆWeek 5-8ï¼‰

#### Week 5-6: åŒ»ç™‚RAGå¼·åŒ–
```
âœ… Tasks:
1. åŒ»ç™‚ã‚³ãƒ¼ãƒ‘ã‚¹çµ±åˆ
   - PubMed abstracts
   - çµ„ç¹”å†…è¨˜éŒ²ï¼ˆ13,500+ï¼‰
   - åŒ»ç™‚ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

2. åŒ»ç™‚å°‚ç”¨Retriever
   - PubMedBERT fine-tuning
   - MedCPTçµ±åˆ
   - Multi-corpus retrieval

3. è‡¨åºŠæ¤œè¨¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
   - å°‚é–€å®¶ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
   - Human-in-the-loopè©•ä¾¡
   - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çµ±åˆ

ğŸ“Š Success Metrics:
- åŒ»ç™‚QAç²¾åº¦ > 75%
- è‡¨åºŠçš„é–¢é€£æ€§ > 0.90
- å°‚é–€å®¶æ‰¿èªç‡ > 90%
```

---

#### Week 7-8: æœ¬ç•ªæœ€é©åŒ–
```
âœ… Tasks:
1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
   - GPUæ¨è«–æœ€é©åŒ–
   - ãƒãƒƒãƒå‡¦ç†
   - ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥

2. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ç¢ºä¿
   - Kubernetes HPAè¨­å®š
   - ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°
   - ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–
   - HIPAAæº–æ‹ ç¢ºèª
   - ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–
   - ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡

ğŸ“Š Success Metrics:
- Latency p95 < 3ç§’
- Throughput > 100 QPS
- ç¨¼åƒç‡ > 99.5%
```

---

### Phase 4: ç¶™ç¶šçš„æ”¹å–„ï¼ˆOngoingï¼‰

```
âœ… Continuous Tasks:
1. A/Bãƒ†ã‚¹ãƒˆ
   - æ–°æ©Ÿèƒ½ã®æ®µéšçš„å±•é–‹
   - ç²¾åº¦æ”¹å–„ã®æ¸¬å®š
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†

2. ãƒ¢ãƒ‡ãƒ«æ›´æ–°
   - Embedding model fine-tuning
   - Reranker modelæ›´æ–°
   - LLM version upgrade

3. ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†
   - å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
   - æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
   - å“è³ªç›£æŸ»

ğŸ“Š Success Metrics:
- æœˆæ¬¡ç²¾åº¦æ”¹å–„ > 2%
- ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦ > 4.0/5.0
- ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç‡ > 99.5%
```

---

## 11. çµè«–

### 11.1 æœ€é‡è¦ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ Top 10

1. **âœ… Hybrid Search (BM25+Dense+Reranking)** - ç²¾åº¦+30-50%ã€å¿…é ˆå®Ÿè£…
2. **âœ… Contextual Retrieval** - å¤±æ•—ç‡-67%ã€ã‚³ã‚¹ãƒˆåŠ¹ç‡æœ€é«˜
3. **âœ… Semantic Chunking** - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ+40-60%ã€ç„¡æ–™ã§åŠ¹æœå¤§
4. **âœ… Cross-Encoder Reranking** - NDCG+0.10ã€åŒ»ç™‚RAGã®æ¨™æº–
5. **âœ… Multi-Query Expansion** - NDCG+22%ã€å®Ÿè£…å®¹æ˜“
6. **âœ… Medical Corpus Integration** - ç²¾åº¦+18%ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã®éµ
7. **âœ… RAGAS Evaluation** - çµ±åˆè©•ä¾¡ã€ç¶™ç¶šçš„æ”¹å–„ã®åŸºç›¤
8. **âœ… Span-level Verification** - Hallucination-70%ã€åŒ»ç™‚å¿…é ˆ
9. **âœ… Production Monitoring** - å“è³ªç¶­æŒã€å•é¡Œæ—©æœŸæ¤œå‡º
10. **âœ… Human-in-the-Loop** - åŒ»ç™‚å®‰å…¨æ€§ã€æœ€çµ‚å“è³ªä¿è¨¼

---

### 11.2 æœŸå¾…ã•ã‚Œã‚‹ç·åˆåŠ¹æœ

#### ç²¾åº¦æ”¹å–„
- **Retrieval Accuracy**: +40-60%
- **Generation Quality**: +20-30%
- **Overall RAGAS Score**: 0.60 â†’ **0.85**
- **Medical QA Accuracy**: 60% â†’ **75-80%**

#### ä¿¡é ¼æ€§å‘ä¸Š
- **Hallucination Rate**: 20% â†’ **<2%**
- **Faithfulness**: 0.80 â†’ **>0.95**
- **User Satisfaction**: 3.5/5.0 â†’ **>4.2/5.0**

#### ã‚³ã‚¹ãƒˆæœ€é©åŒ–
- **Re-ranking**: Cross-Encoderæ¡ç”¨ ($5/æœˆ)
- **Contextual Retrieval**: $1.02/M tokens
- **Total Phase 1**: **$7-10/æœˆ** (äºˆç®—å†…)

---

### 11.3 æˆåŠŸã®ãŸã‚ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ

#### Technical Excellence
1. **æ®µéšçš„å®Ÿè£…**: Phase 1 â†’ Phase 2 â†’ Phase 3
2. **ç¶™ç¶šçš„è©•ä¾¡**: RAGASçµ±åˆã€é€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼
3. **ãƒ‡ãƒ¼ã‚¿å“è³ª**: åŒ»ç™‚ã‚³ãƒ¼ãƒ‘ã‚¹ã®ç¶™ç¶šçš„æ›´æ–°

#### Operational Excellence
1. **ç›£è¦–ä½“åˆ¶**: LangSmithã€ã‚¢ãƒ©ãƒ¼ãƒˆã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
2. **å°‚é–€å®¶é€£æº**: Human-in-the-loopã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—
3. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: HIPAAæº–æ‹ ã€æš—å·åŒ–ã€ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡

#### Business Value
1. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸­å¿ƒ**: <3ç§’å¿œç­”ã€>4.0æº€è¶³åº¦
2. **ã‚³ã‚¹ãƒˆåŠ¹ç‡**: äºˆç®—å†…ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«
3. **ç¶™ç¶šæ”¹å–„**: A/Bãƒ†ã‚¹ãƒˆã€æœˆæ¬¡ç²¾åº¦å‘ä¸Š

---

### 11.4 æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

#### å³æ™‚ï¼ˆä»Šé€±ï¼‰
- [ ] Hybrid SearchåŸºç›¤å®Ÿè£…é–‹å§‹
- [ ] è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ï¼ˆ50ã‚¯ã‚¨ãƒªï¼‰
- [ ] ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š

#### çŸ­æœŸï¼ˆ2é€±é–“ï¼‰
- [ ] Semantic Chunkingé©ç”¨
- [ ] Contextual Retrievalå®Ÿè£…
- [ ] åŒ»ç™‚ç”¨èªè¾æ›¸100èªä½œæˆ

#### ä¸­æœŸï¼ˆ1ãƒ¶æœˆï¼‰
- [ ] RAGASè©•ä¾¡çµ±åˆ
- [ ] æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤
- [ ] å°‚é–€å®¶ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰

---

**æœ€çµ‚æ›´æ–°**: 2025-10-27
**æ¬¡å›ãƒ¬ãƒ“ãƒ¥ãƒ¼**: 2é€±é–“å¾Œï¼ˆå®Ÿè£…é€²æ—ç¢ºèªï¼‰
**æ‰¿èª**:
- [ ] æŠ€è¡“ãƒªãƒ¼ãƒ‰
- [ ] ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
- [ ] åŒ»ç™‚å°‚é–€å®¶

---

## å‚è€ƒæ–‡çŒ®ï¼ˆèª¿æŸ»ã‚½ãƒ¼ã‚¹ä¸€è¦§ï¼‰

### Webè¨˜äº‹ãƒ»ãƒ–ãƒ­ã‚° (15ä»¶)
1. The 2025 Guide to RAG - EdenAI
2. Hybrid Search Revamped - Qdrant
3. Contextual Retrieval - Anthropic
4. RAG Evaluation Metrics - FutureAGI
5. Cross-Encoders Guide - OpenAI Cookbook
6. Chunking Strategy - NVIDIA
7. Ultimate Chunking Guide - Databricks
8. Query Rewriting - Microsoft Azure
9. Medical RAG - NVIDIA Developer
10. Hallucination Mitigation - MDPI
11. Production RAG Deployment - WhyLabs
12. Semantic Chunking - Multimodal.dev
13. RAG Best Practices - Medium (è¤‡æ•°)
14. Advanced RAG - Haystack
15. Ultimate Reranking Guide - ZeroEntropy

### GitHub ãƒªãƒã‚¸ãƒˆãƒª (5ä»¶)
1. github.com/Teddy-XiongGZ/MedRAG
2. github.com/joyceannie/Medical_ChatBot
3. github.com/kolhesamiksha/Hybrid-Search-RAG
4. github.com/Azure-Samples/app-service-rag-openai-ai-search-python
5. github.com/NirDiamant/RAG_Techniques

### å­¦è¡“è«–æ–‡ (2ä»¶)
1. arXiv:2501.07391 - RAG Best Practices
2. arXiv:2408.00727 - i-MedRAG

**ç·èª¿æŸ»ã‚½ãƒ¼ã‚¹æ•°**: 22ä»¶
